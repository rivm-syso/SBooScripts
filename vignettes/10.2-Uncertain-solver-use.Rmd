---
title: "Probabilistic use of SimpleBox"
author: "Anne Hids, Valerie de Rijk, Joris Quik, Jaap Slootweg"
date: "`r Sys.Date()`"
output: github_document
editor_options: 
  chunk_output_type: console
---

SimpleBox (SBoo) has specific solvers available that allow running the model deterministic or probabilistic. We assume you already understand the basics of using SimpleBox and have an idea of what input variables or emissions you want to input with a certain degree of uncertainty or variability. There are basically to types of solvers to use here:

1.  UncertainSolver for running the model n times calculating steady state output (mass/concentration)
2.  UncertainDynamicSolver for running the model n times calculating dynamic output

For both the world needs to be initialized first, in this case for only the Molecular species.

```{r Initialize World, warning=FALSE, message=FALSE}

library(tidyverse)

source("baseScripts/initWorld_onlyMolec.R")
```

## 1. Probabilistic Solver - Steady state

There are two ways to use the UncertainSolver:

1.  With uncertain variables and variable emissions.
2.  With uncertain variables but one set of emissions

Method 1 will be explained first, then method 2.

### 1.1 Uncertain variables and variable emissions case

#### Create tibble with samples for uncertain variables

The first step is to determine the number of uncertain variables, the number of compartments that have emissions and the number of runs.

```{r Create samples, warning=FALSE, message=FALSE}
library(lhs)

n_vars <- 3 # The number of variables you want to create a distribution for
n_emiscomps <- 3 # The number of compartments that have emissions
n_samples <- 100 # The number of samples you want to pull from the distributions for each variable

n_lhs <- n_vars + n_emiscomps # Total number of vectors to create with latin hypercube sampling (lhs)

lhs_samples <- optimumLHS(n_samples, n_lhs) # Generate numbers between 0 and 1 using lhs

# Separate the samples for the variable and emission distributions from each other:
lhs_samples_vars <- lhs_samples[, 1:n_vars] 
lhs_samples_emis <- lhs_samples[, (n_vars + 1):ncol(lhs_samples)]
```

The lhs samples are pulled from a uniform distribution between 0 and 1. So these numbers have to be scaled to the real values you want to use, and it is possible to transform this uniform distribution to a different distribution. In this example, a triangular distribution will be used.

Define triangular distribution function:

```{r Define triangular distribution function, warning=FALSE, message=FALSE}
# Triangular distribution function
triangular_cdf_inv <- function(u, # LH scaling factor
                               a, # Minimum
                               b, # Maximum
                               c) { # Peak value
  ifelse(u < (c-a)/(b-a),
         a + sqrt(u * (b-a) * (c-a)),
         b - sqrt((1-u) * (b-a) * (b-c)))
}
```

##### Prepare variable samples

Now we are ready to prepare the variable data and define the min, max and peak value of the distribution for each variable.

In this example the following three variables are used:

1.  Area for regional sea
2.  Area for regional river
3.  Erosion of agricultural soil

In the chunk below, the name, scale, subcompartment, min, max and peak value are defined for each variable.

```{r Get min, max and peak value of variable values, warning=FALSE, message=FALSE}
# Define the names of the uncertain variables
var1Name <- "kdeg"

var1 <- World$fetchData(var1Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "river")

# Set the parameters for the triangular distribution
var1$a <- var1$kdeg*0.5    # Minimum value
var1$b <- var1$kdeg*1.5    # Maximum value
var1$c <- var1$kdeg        # peak value (peak)

# Define the names of the uncertain variables
var2Name <- "kdeg"

var2 <- World$fetchData(var2Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "air")

# Set the parameters for the triangular distribution
var2$a <- var2$kdeg*0.5    # Minimum value
var2$b <- var2$kdeg*1.5    # Maximum value
var2$c <- var2$kdeg         # peak value (peak)

# Define the names of the uncertain variables
var3Name <- "kdeg"

var3 <- World$fetchData(var3Name) |>
  filter(SubCompart == "agriculturalsoil") |>
  mutate(Scale = NA)

# Set the parameters for the triangular distribution
var3$a <- var3$kdeg*0.5    # Minimum value
var3$b <- var3$kdeg*1.5    # Maximum value
var3$c <- var3$kdeg         # peak value (peak)
```

Now this data needs to be combined into a tibble, and the function for the triangular distribution written earlier is applied to the tibble. The result is a nested tibble, containing the name, scale and subcompartment for each variable, and the sample data is nested.

```{r Scale the samples to the distributions, warning=FALSE, message=FALSE}
params <- tibble(
  varName = c(var1Name, var2Name, var3Name),
  Scale = c(var1$Scale, var2$Scale, var3$Scale),
  SubCompart = c(var1$SubCompart, var2$SubCompart, var3$SubCompart),
  data = list(
    tibble(id = c("a", "b", "c"), value = c(var1$a, var1$b, var1$c)),
    tibble(id = c("a", "b", "c"), value = c(var2$a, var2$b, var2$c)),
    tibble(id = c("a", "b", "c"), value = c(var3$a, var3$b, var3$c))
  )
)

sample_df <- params

# Transform each LHS sample column to the corresponding triangular distribution
for (i in 1:n_vars) {
  a <- filter(params$data[[i]], id == "a") %>% pull(value)
  b <- filter(params$data[[i]], id == "b") %>% pull(value)
  c <- filter(params$data[[i]], id == "c") %>% pull(value)
  
  samples <- triangular_cdf_inv(lhs_samples_vars[, i], a, b, c)
  
  # Create a new tibble for 'data' with samples replacing original values
  new_data <- tibble(value = samples)
  
  # Update the data column in the sample_df
  sample_df$data[[i]] <- new_data
}
```

##### Prepare emission data

In this example, we will take a steady state emission data frame as the starting point for creating the triangular distributions. You could also directly enter the min, max and peak values if you have them.

```{r Create steady state emission dataframe, warning=FALSE, message=FALSE}
# Create the steady state emission dataframe
emissions <- data.frame(Abbr = c("aRU", "s2RU", "w1RU"), Emis = c(10000, 10000, 10000)) # convert 1 t/y to si units: kg/s

MW <- World$fetchData("MW")

emissions <- emissions |>
  mutate(Emis = Emis*1000/(365*24*60*60)) 

```

Now that the emission data frame is made, we can scale the samples we took earlier to the triangular distribution just like we did for the variables.

```{r Scale the emissions to the distributions, warning=FALSE, message=FALSE}

# Define the names of the uncertain variables
comp1Name <- "aRU"

comp1 <-  emissions |>
  filter(Abbr == comp1Name)

# Set the parameters for the triangular distribution
comp1$a <- comp1$Emis*0.7    # Minimum value
comp1$b <- comp1$Emis*1.3    # Maximum value
comp1$c <- comp1$Emis        # peak value (peak)

comp1 <- comp1 |>
  select(-Emis)

# Define the names of the uncertain variables
comp2Name <- "s2RU"

comp2 <-  emissions |>
  filter(Abbr == comp2Name)

# Set the parameters for the triangular distribution
comp2$a <- comp2$Emis*0.7    # Minimum value
comp2$b <- comp2$Emis*1.3    # Maximum value
comp2$c <- comp2$Emis        # peak value (peak)

comp2 <- comp2 |>
  select(-Emis)

# Define the names of the uncertain variables
comp3Name <- "w1RU"

comp3 <-  emissions |>
  filter(Abbr == comp3Name)

# Set the parameters for the triangular distribution
comp3$a <- comp3$Emis*0.7    # Minimum value
comp3$b <- comp3$Emis*1.3    # Maximum value
comp3$c <- comp3$Emis        # peak value (peak)

comp3 <- comp3 |>
  select(-Emis)

params <- tibble(
  Abbr = c(comp1Name, comp2Name, comp3Name),
  Emis = list(
    tibble(id = c("a", "b", "c"), value = c(comp1$a, comp1$b, comp1$c)),
    tibble(id = c("a", "b", "c"), value = c(comp2$a, comp2$b, comp2$c)),
    tibble(id = c("a", "b", "c"), value = c(comp3$a, comp3$b, comp3$c))
  )
)

emis_df <- params

# Transform each LHS sample column to the corresponding triangular distribution
for (i in 1:n_emiscomps) {
  a <- filter(params$Emis[[i]], id == "a") %>% pull(value)
  b <- filter(params$Emis[[i]], id == "b") %>% pull(value)
  c <- filter(params$Emis[[i]], id == "c") %>% pull(value)
  
  samples <- triangular_cdf_inv(lhs_samples_emis[, i], a, b, c)
  
  # Create a new tibble for 'data' with samples replacing original values
  new_data <- tibble(value = samples)
  
  # Update the data column in the sample_df
  emis_df$Emis[[i]] <- new_data
}

```

#### Solve

The UncertainSolver is needed to apply simplebox probabilistically using a tibble with nested samples.

```{r Solve, warning=FALSE, message=FALSE}
World$NewSolver("UncertainSolver")
solved <- World$Solve(emis_df, needdebug = F, sample_df)

```

# Make plots for every variable

```{r Data preparation for plots}
Input_Variables <- 
  solved$Input_Variables |> unnest(data) 
Input_Emission <- 
  solved$Input_Emission |> unnest(Emis) 

Plot_data <- 
  Input_Variables |> 
# some units missing resulting in NA
  pivot_wider(names_from = c(varName,Scale,SubCompart,Unit), values_from = value) |> 
  full_join(solved$SteadyStateMass) |>
  full_join(Input_Emission, by = c("Abbr", "RUN"))

varnames <- colnames(Plot_data)[2:(1+n_vars)]

plot_theme <-  theme(
    axis.title.x = element_text(size = 14),    
    axis.title.y = element_text(size = 14),    
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),     
    axis.text.y = element_text(size = 12),
    title = element_text(size=20)
  )

emiscomps <- unique(solved$Input_Emission$Abbr)

```

```{r Plots}
p1 <- ggplot(Plot_data, mapping = aes(x=varnames[1], y = EqMass)) +
  geom_point() + facet_wrap(vars(Abbr)) +
  scale_y_continuous(trans = 'log10')
p1

p2_data <-
  Plot_data |> pivot_longer(varnames,
                            values_to = "Variable value",
                            names_to = "Variable") |>
  filter(SubCompart == "river")

p2 <-  ggplot(p2_data, mapping = aes(x=`Variable value`, y = EqMass)) +
  geom_point() + facet_wrap(vars(Scale,SubCompart,Variable)) +
  scale_y_continuous(trans = 'log10')
p2

# p3_data <-
#   Input_Emission |> pivot_wider(names_from = c(Abbr,Unit), names_glue = "{Abbr}_Emis_{Unit}",
#                                 values_from = Emis) |>
#   full_join(solved$SteadyStateMass) |>   filter(SubCompart == "river") |>
#   pivot_longer(c(`aRU_Emis_kg.s-1`,`s2RU_Emis_kg.s-1`), values_to = "Emission_kg.s-1",names_to = "EmisComp")
# 
# p3 <-  ggplot(p3_data, mapping = aes(x=`Emission_kg.s-1`, y = EqMass)) +
#   geom_point() + facet_wrap(vars(Scale,SubCompart,EmisComp))
# p3

plots_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

for(i in varnames) {
  p2 <- ggplot(plots_data, mapping = aes(x = .data[[i]], y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) + 
  ggtitle("Mass in compartment at year ") + 
  labs(subtitle = "Uncertain emissions",
       x = i,  
       y = "Mass (kg)") +
  plot_theme                 
print(p2)
}

# Filter the plot data for the compartments that received emissions
EM_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

# Plot the emissions against the masses for these compartments
EM_p1 <- ggplot(EM_data, mapping = aes(x = value, y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) +
  ggtitle("Relation between emissions and mass") + 
  labs(subtitle = "Uncertain emissions",
       x = "Emissions (kg/s)",
       y = "Mass (kg)") + 
  plot_theme
EM_p1

```

### 1.2 Uncertain variables and deterministic emission case

#### Create tibble with samples for uncertain variables

Because we only use one set of emissions, we only have to create samples for the number of variables we want to use.

```{r Create samples 2, warning=FALSE, message=FALSE}
n_vars <- 3 # The number of variables you want to create a distribution for
n_samples <- 100 # The number of samples you want to pull from the distributions for each variable

lhs_samples <- optimumLHS(n_samples, n_vars) # Generate numbers between 0 and 1 using lhs
```

The rest of the steps to create the dataframe with samples are the same as for method 1.

```{r Get min, max and peak value of variable values, warning=FALSE, message=FALSE}
# Define the names of the uncertain variables
var1Name <- "kdeg"

var1 <- World$fetchData(var1Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "river")

# Set the parameters for the triangular distribution
var1$a <- var1$kdeg*0.5    # Minimum value
var1$b <- var1$kdeg*1.5    # Maximum value
var1$c <- var1$kdeg        # peak value (peak)

# Define the names of the uncertain variables
var2Name <- "kdeg"

var2 <- World$fetchData(var2Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "air")

# Set the parameters for the triangular distribution
var2$a <- var2$kdeg*0.5    # Minimum value
var2$b <- var2$kdeg*1.5    # Maximum value
var2$c <- var2$kdeg         # peak value (peak)

# Define the names of the uncertain variables
var3Name <- "kdeg"

var3 <- World$fetchData(var3Name) |>
  filter(SubCompart == "agriculturalsoil") |>
  mutate(Scale = NA)

# Set the parameters for the triangular distribution
var3$a <- var3$kdeg*0.5    # Minimum value
var3$b <- var3$kdeg*1.5    # Maximum value
var3$c <- var3$kdeg         # peak value (peak)
```

Now this data needs to be combined into a tibble, and the function for the triangular distribution written earlier is applied to the tibble. The result is a nested tibble, containing the name, scale and subcompartment for each variable, and the sample data is nested. 

```{r Scale the samples to the distributions, warning=FALSE, message=FALSE}
params <- tibble(
  varName = c(var1Name, var2Name, var3Name),
  Scale = c(var1$Scale, var2$Scale, var3$Scale),
  SubCompart = c(var1$SubCompart, var2$SubCompart, var3$SubCompart),
  data = list(
    tibble(id = c("a", "b", "c"), value = c(var1$a, var1$b, var1$c)),
    tibble(id = c("a", "b", "c"), value = c(var2$a, var2$b, var2$c)),
    tibble(id = c("a", "b", "c"), value = c(var3$a, var3$b, var3$c))
  )
)

sample_df <- params

# Transform each LHS sample column to the corresponding triangular distribution
for (i in 1:n_vars) {
  a <- filter(params$data[[i]], id == "a") %>% pull(value)
  b <- filter(params$data[[i]], id == "b") %>% pull(value)
  c <- filter(params$data[[i]], id == "c") %>% pull(value)
  
  samples <- triangular_cdf_inv(lhs_samples_vars[, i], a, b, c)
  
  # Create a new tibble for 'data' with samples replacing original values
  new_data <- tibble(value = samples)
  
  # Update the data column in the sample_df
  sample_df$data[[i]] <- new_data
}
```

#### Prepare emission data

When using this method, all we need is one steady state dataframe with emissions.

```{r Create steady state emission dataframe 2, warning=FALSE, message=FALSE}
# Create the steady state emission dataframe
emissions <- data.frame(Abbr = c("aRU", "s2RU", "w1RU"), Emis = c(10000, 10000, 10000)) # convert 1 t/y to si units: kg/s

MW <- World$fetchData("MW")

emissions <- emissions |>
  mutate(Emis = Emis*1000/(365*24*60*60)) 

```

#### Solve

```{r Solve 2, warning=FALSE, message=FALSE}
World$NewSolver("UncertainSolver")

solved <- World$Solve(emissions, needdebug = F, sample_df)
```

#### Make plots

```{r Data preparation for plots}
Input_Variables <- 
  solved$Input_Variables |> unnest(data) 
Input_Emission <- 
  solved$Input_Emission |> unnest(Emis) 

Plot_data <- 
  Input_Variables |> 
# some units missing resulting in NA
  pivot_wider(names_from = c(varName,Scale,SubCompart,Unit), values_from = value) |> 
  full_join(solved$SteadyStateMass)

varnames <- colnames(Plot_data)[2:(1+n_vars)]

plot_theme <-  theme(
    axis.title.x = element_text(size = 14),    
    axis.title.y = element_text(size = 14),    
    axis.text.x = element_text(size = 12,angle = 45, hjust = 1),     
    axis.text.y = element_text(size = 12),
    title = element_text(size=20)
  )

emiscomps <- unique(solved$Input_Emission$Abbr)

```

```{r Plots}
p1 <- ggplot(Plot_data, mapping = aes(x=varnames[1], y = EqMass)) +
  geom_point() + facet_wrap(vars(Abbr)) +
  scale_y_continuous(trans = 'log10')
p1

p2_data <-
  Plot_data |> pivot_longer(varnames,
                            values_to = "Variable value",
                            names_to = "Variable") |>
  filter(SubCompart == "river")

p2 <-  ggplot(p2_data, mapping = aes(x=`Variable value`, y = EqMass)) +
  geom_point() + facet_wrap(vars(Scale,SubCompart,Variable)) +
  scale_y_continuous(trans = 'log10')
p2

# p3_data <-
#   Input_Emission |> pivot_wider(names_from = c(Abbr,Unit), names_glue = "{Abbr}_Emis_{Unit}",
#                                 values_from = Emis) |>
#   full_join(solved$SteadyStateMass, by = "Abbr") |>   filter(SubCompart == "river") |>
#   pivot_longer(c(`aRU_Emis_kg.s-1`,`s2RU_Emis_kg.s-1`), values_to = "Emission_kg.s-1",names_to = "EmisComp")
# 
# p3 <-  ggplot(p3_data, mapping = aes(x=`Emission_kg.s-1`, y = EqMass)) +
#   geom_point() + facet_wrap(vars(Scale,SubCompart,EmisComp)) 
# p3

plots_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

for(i in varnames) {
  p2 <- ggplot(plots_data, mapping = aes(x = .data[[i]], y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) + 
  ggtitle("Mass in compartment at year ") + 
  labs(subtitle = "One set of emissions",
       x = i,  
       y = "Mass (kg)") +
  plot_theme                 
print(p2)
}

```

## 2. Probabilistic Dynamic Solver 
