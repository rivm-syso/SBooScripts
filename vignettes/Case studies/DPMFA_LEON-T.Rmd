---
title: "DPMFA LEON-T"
author: "Anne Hids"
date: "`r Sys.Date()`"
output: github_document
editor_options: 
  chunk_output_type: console
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::knit_meta()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
projectRoot <- paste(getwd(), "..", "..", sep = "/")
knitr::opts_knit$set(root.dir = projectRoot) 
```

# *Initializing World and Substance*

Depending on the substance you want to analyze, a selection needs to be
made from the three different"worlds" : Molecular, Particulate and
Plastics. Here, we initialize the world for plastics.

```{r Initialize World}
library(lhs)
library(readxl)
library(viridis)
library(doParallel)
library(trapezoid)

source("baseScripts/initWorld_onlyPlastics.R")

World$substance <- "microplastic"
```

# Load the DPMFA data and make a nested emission dataframe

```{r Load DPMFA data}

# for local case study folder:
abspath <- "vignettes/Case Studies/CaseData/Baseline_PMFA_EU.RData"

load(abspath)

# Check if the loaded data is DPMFA or PMFA data
if(exists("DPMFA_stocks")) {
  type <- "DPMFA"
} else {
  type <- "PMFA"
}

# Convert to long format
data_long <- 
  DPMFA_sink |> unnest(Mass_Polymer_kt, keep_empty = TRUE) |> 
  pivot_longer(cols=-c(Type, Scale, Source, Polymer, To_Compartment, Material_Type, iD_source, RUN),
               names_to = "Year",
               values_to = "Mass_Polymer_kt") 

source_names <- unique(data_long$Source)

print(source_names)

source_of_interest <- c("Tyre wear")

if (all(!is.na(source_of_interest))) {
  # Check if all the elements of source_of_interest are present in data_long$Source
  if (!all(source_of_interest %in% unique(data_long$Source))) {
    print("Selected source(s) not in dataframe")
  } else {
    sources <- source_of_interest
  }
} else if (all(is.na(source_of_interest))) {
  # If all elements are NA, return all unique sources
  sources <- unique(data_long$Source)
}

# Calculate kg/s from kt/y 
data_summed <- data_long |>
  filter(Source %in% sources) |>
  mutate(Mass_Polymer_kg_s = Mass_Polymer_kt*1000000/(365.25*24*3600)) |>
  filter(Material_Type == "micro") 

if(unique(data_long$Scale) == "EU"){
  SBscale <- "C"
} else if (unique(data_long$Scale) == "NL") {
  SBscale <- "R"
}

# Select data for 2019
y <- 2019

# Assign SB compartments to DPMFA compartments
data_filtered <- data_summed |>
  filter(Year == y) |>
  select(Source, To_Compartment, Mass_Polymer_kg_s, Year, RUN, Polymer) |>
  mutate(Scale = SBscale) |>
  filter(To_Compartment != "Sub-surface soil (micro)") |> # Exclude sub-surface soil because this is currently outside the scope of SimpleBox
  mutate(Compartment = case_when(
    str_detect(To_Compartment, "soil") ~ "s",
    str_detect(To_Compartment, "water") ~ "w",
    str_detect(To_Compartment, "air") ~ "a"
  )) |>
  mutate(Subcompartment = case_when(
    str_detect(To_Compartment, "Agricultural") ~ "2",
    str_detect(To_Compartment, "Natural") ~ "1",
    str_detect(To_Compartment, "Road side") ~ "3",
    str_detect(To_Compartment, "Residential") ~ "3",
    str_detect(To_Compartment, "Sea") ~ "2",
    str_detect(To_Compartment, "Surface") ~ "1",
    str_detect(To_Compartment, "Outdoor") ~ ""
  )) |>
  mutate(Species = case_when(
    Source == "Tyre wear" ~ "P",
    TRUE ~ "S")) |>
  mutate(Abbr = paste0(Compartment, Subcompartment, Scale, Species)) |>
  group_by(Source, Abbr, Year, RUN, Polymer) |>
  summarise(Mass_Polymer_kg_s = sum(Mass_Polymer_kg_s)) |>
  ungroup() |>
  rename(value = Mass_Polymer_kg_s) |>
  select(Source, Abbr, Year, Polymer, value, RUN)

```

```{r Make a separate emission df for every polymer}
runs <- 1000
TESTING = T
if(TESTING==TRUE) data_filtered <- data_filtered |> filter(RUN<(runs+1))

unique_combinations <- data_filtered |>
  distinct(Source, Polymer)

emis_df_names <- c()

for(i in 1:nrow(unique_combinations)){
  source <- unique_combinations$Source[i]
  pol <- unique_combinations$Polymer[i]
  
  filtered <- data_filtered |>
    filter(Polymer == pol)
  
  if(type == "DPMFA"){
    # Make an emission dataframe for the dynamic uncertain solver
    emis_df_dyn <- filtered |>
      group_by(Abbr, Year) |>
      rename(Timed = Year) |>
      mutate(Timed = as.double(Timed)*(365.25*24*3600)) |>
      nest(Emis = c(RUN, value)) 
    
    emis_df_name <- paste0("emis_dyn_", source, "_", pol)
    
    assign(emis_df_name, emis_df_dyn)
    
    emis_df_names <- c(emis_df_names, emis_df_name)
    
    ymin <- min(emis_df_dyn$Year)
    ymax <- max(emis_df_dyn$Year)
    
  } else if(type == "PMFA"){
    
    # Make an emission dataframe for the steady uncertain solver
    emis_df_ss <- filtered |>
      nest(Emis = c(RUN, value)) 
    
    source_name <- str_replace_all(source, "[()]", "")  # Remove parentheses
    source_name <- str_replace_all(source, " ", "_")   # Replace spaces with underscores
    
    emis_df_name <- paste0("emis_ss_", source_name, "_", pol)
    
    assign(emis_df_name, emis_df_ss)
    
    emis_df_names <- c(emis_df_names, emis_df_name)
  }
}
```

For the source tyre wear, we want to estimate the concentration of TWP in road side soil. We will do this by rescaling the othersoil compartment to the size of road side soil in the EU. 

To estimate this, two datapoints are needed: 
- The total road length in the EU (https://erf.be/statistics/road-network-2024/)
- The mean width of road side soil (2m, based on LEON-T deliverable 3.2, figure 23)

```{r Estimate area of road side soil in the EU}
path_dist <- "vignettes/Case studies/CaseData/Road_network_data.xlsx"
RN_data <- read_excel(path_dist, sheet = "Data") 

# Sum the data to get the total length of the road network in EU27 countries
road_length_EU <- sum(RN_data$Total)
RL_m <- road_length_EU*1000 

# Multiply the road length with the width of roadside soil on both sides of the road
RSS_width <- 2 #in meters
RSS_area_EU <- RL_m*RSS_width*2 # Total area of roadside soil in the EU27 in m^2

# Check the current value for other soil area in SimpleBox on continental scale
soil_areas <- World$fetchData("Area") |>
  filter(Scale == "Continental") |>
  filter(SubCompart == "othersoil" | SubCompart == "naturalsoil" | SubCompart == "agriculturalsoil")

# Calculate the areas of natural and agriculturalsoil again, so that the total soil area stays the same
nat_fraction <- soil_areas$Area[2]/(soil_areas$Area[1]+soil_areas$Area[2])
nat_area <- ((sum(soil_areas$Area) - RSS_area_EU))*nat_fraction
agri_area <- sum(soil_areas$Area)-nat_area

soil_areas <- soil_areas |>
mutate(new_area = case_when(
    SubCompart == "othersoil" ~ RSS_area_EU,
    SubCompart == "naturalsoil" ~ nat_area,
    SubCompart == "agriculturalsoil" ~ agri_area
  ))

```

```{r Functions for distributions}
# Define triangular distribution function
triangular <- function(u, a, b, c) {               # u = samples, a = min, b = max, c = peak
  ifelse(u < (c-a)/(b-a),
         a + sqrt(u * (b-a) * (c-a)),
         b - sqrt((1-u) * (b-a) * (b-c)))
}

# Define uniform distribution function
uniform <- function(u, a, b) {                     # u = samples, a = min, b = max
  transformed_samples <- a + (b - a) * u
  return(transformed_samples)
}

# Define power law distribution function
power_law <- function(u, a, b, c){                 # u = samples, a = min, b = max, c = alpha
  
  # Ensure that samples are within [0, 1]
  samples <- pmin(pmax(u, 0), 1)
  
  # Transform samples to the power-law distribution
  scaled_samples <- a * ((b / a) ^ samples) ^ (1 / (1 - c))
  
  return(scaled_samples)
}

trapezoidal <- function(u, a, b, c, d) {
  # Ensure u is in the range [0, 1]
  u <- pmin(pmax(u, 0), 1)  # Clip u to [0, 1]
  
  # Total width of the trapezoid
  width_total <- d - a
  base1 <- b - a    # Width of the left base
  base2 <- d - c    # Width of the right base
  
  # Calculate the CDF segments
  CDF_left <- base1 / width_total         # Area under the left triangle
  CDF_flat <- 1 - base2 / width_total     # Area under the flat top
  
  result <- ifelse(u < (base1 / width_total), 
                   a + sqrt(u * (base1) * width_total),  # Left triangle
                   ifelse(u <= (CDF_flat + base1 / width_total), 
                          b + (u - base1 / width_total) * (d - b),  # Flat top
                          d - sqrt((1 - u) * (base2) * width_total)  # Right triangle
                   )
  )
  
  return(result)
}

```

# Create dataset with uncertain variables

## Prepare excel data

```{r}
# Path to excel file with distribution values
path_dist <- "vignettes/Case studies/CaseData/Microplastic_variables_v2.xlsx"

excel_df <- read_excel(path_dist, sheet = "Polymer_data") 

materials <- unique(excel_df$Polymer)

all_subcomparts <- World$fetchData("SubCompartName")$SubCompart
soil <- all_subcomparts[str_detect(all_subcomparts, "soil")]
sediment <- all_subcomparts[str_detect(all_subcomparts, "sediment")]
air <- str_detect(all_subcomparts, "air|cloudwater")
water <- all_subcomparts[!grepl("soil|sediment|air|cloudwater", all_subcomparts)]
soil_sediment <- c(soil, sediment)
materials <- unique(data_filtered$Polymer)
species <- World$fetchData("SpeciesName")$Species[!grepl("Unbound", World$fetchData("SpeciesName")$Species)]
small_large <- species[!grepl("Solid", species)]
scales <- World$fetchData("ScaleName")$Scale

explode <- function(df, target_col, explode_value, new_values) {
  df %>%
    # Use mutate to create a new column if the target column equals explode_value
    mutate(!!sym(target_col) := ifelse(!!sym(target_col) == explode_value, list(new_values), !!sym(target_col))) %>%
    # Unnest the target column to duplicate rows
    unnest(!!sym(target_col))
}

# Repeat the rows where Polymer == "any" for every polymer present in the filtered DPMFA data
suppressWarnings({
  var_df <- explode(excel_df, target_col = "Polymer", explode_value = "any", new_values = materials) |>
    mutate(across(c(a, b, c, d), as.numeric)) |>
    mutate(across(c(a, b, c, d), ~ case_when(
      str_detect(Unit, "um") ~ . * 1000,
      TRUE ~ .
    ))) |>
    mutate(Unit = case_when(
      str_detect(Unit, "um") ~ "nm",
      TRUE ~ Unit
    ))
})
```

```{r}
# Generate the correct number of samples
n_samples <- nrow(emis_df_ss$Emis[[1]]) # Number of emission runs 
source_names <- c()
sample_df_names <- c()

for(i in 1:nrow(unique_combinations)){
  source <- unique_combinations$Source[i]
  pol <- unique_combinations$Polymer[i]
  
  # Filter the dataframe for the source and polymer 
  filtered_excel_vars <- var_df |>
    filter(if_all(c(Distribution, a, b), ~ !is.na(.))) |>
    filter(Polymer == pol) |>
    group_by(VarName, Scale, SubCompart, Species, Polymer) |>
    filter(if (n() > 1) MP_source == source | (MP_source == "" & !any(MP_source == source)) else TRUE) %>%
    ungroup()
  
  varnames <- filtered_excel_vars$VarName
  
  n_vars <- nrow(filtered_excel_vars)
  
  # Generate LHS
  lhs_samples <- randomLHS(n_samples, n_vars)
  var_df_names <- c()
  
  for(j in 1:nrow(filtered_excel_vars)){
    filtered_excel_row <- filtered_excel_vars[j, ]
    
    varname <- filtered_excel_row$VarName
    
    filtered_excel_row <- filtered_excel_row |>
      select(VarName, Scale, SubCompart, Species, a, b, c, d)
    
    name <- paste0("var", j)
    var_df_names <- c(var_df_names, name)
    
    assign(name, filtered_excel_row)
  }  
  
  params <- tibble(
    varName = sapply(var_df_names, function(v) get(v)$VarName),
    Scale = sapply(var_df_names, function(v) get(v)$Scale),
    SubCompart = sapply(var_df_names, function(v) get(v)$SubCompart),
    Species = sapply(var_df_names, function(v) get(v)$Species),
    data = lapply(var_df_names, function(v) {
      df <- get(v)
      tibble(id = c("a", "b", "c", "d"), value = c(df$a, df$b, df$c, df$d))
    }))
  
  sample_df <- params
  
  # Transform each LHS sample column to the corresponding  distribution
  for (k in 1:n_vars) {
    a <- filter(params$data[[k]], id == "a") |> pull(value)
    b <- filter(params$data[[k]], id == "b") |> pull(value)
    c <- filter(params$data[[k]], id == "c") |> pull(value)
    d <- filter(params$data[[k]], id == "d") |> pull(value)
    
    if(filtered_excel_vars$Distribution[k] == "Triangular"){
      samples <- triangular(lhs_samples[, k], a, b, c)
    } else if(filtered_excel_vars$Distribution[k] == "Uniform"){
      samples <- uniform(lhs_samples[, k], a, b)
    } else if(filtered_excel_vars$Distribution[k] == "Powerlaw"){
      samples <- power_law(lhs_samples[, k], a, b, c)
    } else if(filtered_excel_vars$Distribution[k] == "Trapezoidal"){
      samples <- trapezoidal(lhs_samples[, k], a, b, c, d)
    }
    
    # Create a new tibble for 'data' with samples replacing original values
    new_data <- tibble(value = samples)
    
    # Update the data column in the sample_df
    sample_df$data[[k]] <- new_data
  }
    
  source_name <- str_replace_all(source, "[()]", "")  # Remove parentheses
  source_name <- str_replace_all(source, " ", "_")   # Replace spaces with underscores
  source_names <- paste0(source_names, source_name)
  
  # Alter the area of the soil compartments if the source is tyre wear
  if(source == "Tyre wear"){
    soil_areas <- soil_areas |>
      rowwise() |>
      mutate(varName = "Area") |>
      mutate(data = list(tibble(value = rep(new_area, n_samples)))) |>
      select(Scale, SubCompart, varName, data) |>
      mutate(Species = NA) 
    
    sample_df <- rbind(sample_df, soil_areas)
  }
  
  # Save a separate dataframe for each material
  sample_df_name <- paste0("sample_df_", source_name, "_", pol)
  sample_df_names <- c(sample_df_names, sample_df_name)
  
  assign(sample_df_name, sample_df)
  
  sample_dfs <- lapply(sample_df_names, get)
}


# Function to process each dataframe
process_sample_df <- function(sample_df, # data frame with nested samples in data
                              scales=c("Arctic", "Tropic", "Moderate", "Regional", "Continental"), # all SimpleBox scales
                              water=c("lake", "sea", "deepocean", "river"), # all SimpleBox water compartments
                              soil_sediment=c("marinesediment", "freshwatersediment", 
                                              "lakesediment","naturalsoil", 
                                              "agriculturalsoil", "othersoil"), # all SimpleBox soil and sediment compartments
                              species=c("Large", "Small", "Solid"), # all SimpleBox species
                              small_large=c("Small", "Large"), # all small and large SimpleBox names
                              all_subcomparts=c("air", "cloudwater","marinesediment", "freshwatersediment", 
                                       "lakesediment","naturalsoil", 
                                       "agriculturalsoil", "othersoil",
                                       "lake", "sea", "deepocean", "river"), # all SimpleBox subcompartment names
                              soil=c("naturalsoil", "agriculturalsoil", "othersoil")) { # all SimpleBox soil compartments
  exploded_scales <- explode(sample_df, target_col = "Scale", explode_value = "any", new_values = scales)
  exploded_water <- explode(exploded_scales, target_col = "SubCompart", explode_value = "Water", new_values = water)
  exploded_soil_sediment <- explode(exploded_water, target_col = "SubCompart", explode_value = "Soil_Sediment", new_values = soil_sediment)
  exploded_species <- explode(exploded_soil_sediment, target_col = "Species", explode_value = "any", new_values = species)
  exploded_small_large <- explode(exploded_species, target_col = "Species", explode_value = "Small_Large", new_values = small_large)
  exploded_subcomparts <- explode(exploded_small_large, target_col = "SubCompart", explode_value = "any", new_values = all_subcomparts)
  exploded_soil <- explode(exploded_subcomparts, target_col = "SubCompart", explode_value = "Soil", new_values = soil)
  
  sample_df_cleaned <- exploded_soil
  
  return(sample_df_cleaned)
}

# Apply the processing function to each dataframe in the list
cleaned_dfs <- lapply(sample_dfs, process_sample_df)

# Assign the cleaned dataframes back to their original names in the global environment
names(cleaned_dfs) <- sample_df_names
list2env(cleaned_dfs, envir = .GlobalEnv)

```

```{r Make some figures to show the values chosen from the distributions}
alpha_water <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "alpha") |>
  filter(SubCompart == "sea") |>
  filter(Species == "Small") 

alpha_water <- alpha_water$data[[1]]

# Make some figures of the distributions
ggplot(alpha_water, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of attachment efficiency for water compartments",
       x = "Alpha") + scale_x_continuous(trans='log10') +
  theme_classic()

alpha_soil <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "alpha") |>
  filter(SubCompart == "naturalsoil") |>
  filter(Species == "Small") 

alpha_soil <- alpha_soil$data[[1]]

# Make some figures of the distributions
ggplot(alpha_soil, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of attachment efficiency for soil and sediment compartments",
       x = "Alpha")+
  theme_classic()

rads <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "RadS")

rads <- rads$data[[1]]

ggplot(rads, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of particle radius",
       x = "Radius (nm)")+
  theme_classic()

rhos <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "RhoS")

rhos <- rhos$data[[1]]

ggplot(rhos, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of density",
       x = "Density (g/m^3)")+
  theme_classic()

kdeg_soil <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "kdeg") |>
  filter(SubCompart == "naturalsoil") |>
  filter(Species == "Small") 

kdeg_soil <- kdeg_soil$data[[1]]

# Make some figures of the distributions
ggplot(kdeg_soil, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of degradation rate constant for soil and sediment compartments",
       x = "Degradation rate constant (s-1)")+
  theme_classic()

kdeg_water <- sample_df_Tyre_wear_RUBBER |>
  filter(varName == "kdeg") |>
  filter(SubCompart == "sea") |>
  filter(Species == "Small") 

kdeg_water <- kdeg_water$data[[1]]

# Make some figures of the distributions
ggplot(kdeg_water, mapping = aes(x = value)) +
  geom_histogram(bins=50, color="#00AFBB", fill=NA) +
  labs(title = "Distribution of degradation rate constant for water compartments",
       x = "Degradation rate constant (s-1)")+
  theme_classic()
```

# Solve the matrix and calculate concentrations

Solve the matrix depending on the type of input emissions given (PMFA =
Steady state, DPMFA = dynamic)

```{r Solve steady state}
start_time <- Sys.time()
solved_df_names <- c()
concentration_df_names <- c()

if(type == "PMFA"){ 
  World$NewSolver("UncertainSolver")
  
  for(i in 1:nrow(unique_combinations)){
    source <- unique_combinations$Source[i]
    source <- str_replace_all(source, "[()]", "")  # Remove parentheses
    source <- str_replace_all(source, " ", "_")   # Replace spaces with underscores
    pol <- unique_combinations$Polymer[i]
    
    # Get the emissions (kg)
    emis_df_name <- emis_df_names[i]
    sample_df_name <- sample_df_names[i]
    
    solved <- World$Solve(get(emis_df_name), needdebug = FALSE, get(sample_df_name))
    solved_df_name <- paste0("solved_ss_", source, "_", pol)
    assign(solved_df_name, solved)
    solved_df_names <- c(solved_df_names, solved_df_name)
    
    # Get the concentrations
    conc <- World$GetConcentration()
    conc_df_name <- paste0("concentration_ss_", source, "_", pol)  
    assign(conc_df_name, conc)
    concentration_df_names <- c(concentration_df_names, conc_df_name)
  }
  
} else if(type == "DPMFA"){
  World$NewSolver("UncertainDynamicSolver")
  
  for(i in 1:nrow(unique_combinations)){
    source <- unique_combinations$Source[i]
    pol <- unique_combinations$Polymer[i]
    emis_df_name <- paste0("emis_dyn_", pol)
    sample_df_name <- pasteo("sample_df_", pol)
    
    solved <- World$Solve(World$Solve(get(pol)), sample_df, tmax = tmax, needdebug = F)
    assign(paste0("solved_dyn_", pol), solved)
    
    # Get the concentrations
    conc_df_name <- paste0("solution_", pol)
    conc <- World$GetConcentration()
    
    assign(conc_df_name, conc)
  }
}
end_time <- Sys.time()

elapsed_time <- end_time - start_time

print(paste0("Elapsed time is ", elapsed_time))

```

# Prep data and make plots

```{r Initialize theme}

# Create a plot theme
plot_theme <-  theme(
  axis.title.x = element_text(size = 14),    
  axis.title.y = element_text(size = 14),    
  axis.text.x = element_text(size = 12, angle = 45, hjust = 1),     
  axis.text.y = element_text(size = 12),
  title = element_text(size=20),
  panel.background = element_rect(fill = "white"),  
  panel.grid.major = element_line(color = "lightgrey", size = 0.5),  
  panel.grid.minor = element_line(color = "lightgrey", size = 0.5)
)

```

```{r Make Mass plots}

date <- Sys.Date()

if(type == "PMFA"){
  for(name in solved_df_names){
    solution_name <- name
    
    Solution <- get(solution_name)$SteadyStateMass |>
      mutate(RUN = as.integer(RUN)) |>
      mutate(EqMass = as.double(EqMass)) 
    
    source <- str_remove(solution_name, "solved_ss_") |> 
          str_replace("_[^_]*$", "") |>  # Removes everything after the last underscore
          str_replace_all("_", " ")      # Replaces all underscores with spaces
    
    pol <- str_extract(solution_name, "(?<=_)[^_]*$")
    
    subt <- paste0(source, ", ", pol, ", ", y)
    
    # Aggregate plot data for all species
    Plot_data_agg <- Solution |>
      mutate(SubCompart = case_when(
        SubCompart == "cloudwater" ~ "air",
        TRUE ~ SubCompart
      )) |>
      group_by(Scale, SubCompart, RUN, Unit) |>
      summarise(EqMass = sum(EqMass)) 
      
    scales <- unique(Plot_data_agg$Scale)
    
    # Make plots for each scale
    for (scale in scales) {
      plot_data_scale <- Plot_data_agg |>
        filter(Scale == scale) |>
        mutate(concname = paste0(SubCompart, " (", Unit, ")"))
      
      # Filter out the compartments without mass
      masscomps <- plot_data_scale |>
        filter(RUN == 1) |>
        filter(EqMass != 0)
      
      masscomps <- masscomps$SubCompart
      
      plot_data_scale <- plot_data_scale |>
        filter(SubCompart %in% masscomps) 
      
      if(source == "Tyre wear"){
        plot_data_scale <- plot_data_scale |>
          mutate(SubCompart = case_when(
            SubCompart == "othersoil" ~ "roadsidesoil",
            TRUE ~ SubCompart
          ))
      }
      
      # Mass plot
      mass_p <- ggplot(plot_data_scale, mapping = aes(x = SubCompart, y = EqMass, fill = SubCompart)) +  
        geom_violin() + 
        labs(title = paste0("Masses at ", scale, " scale"),
             subtitle = subt,
             x = "Compartment",
             y = "Mass (kg)") +
        plot_theme +
        scale_y_continuous(trans = 'log10') +
        scale_fill_viridis_d() + 
        theme(axis.text.x = element_blank(),  
              legend.position = "bottom") +   
        guides(fill = guide_legend(title = NULL)) + 
      scale_y_log10(  # Apply logarithmic scale
      # Major breaks at powers of 10
      breaks = scales::trans_breaks("log10", function(x) 10^x),
      
      # Labels in human-readable form
      labels = scales::trans_format("log10", scales::math_format(10^.x)),
    ) 
      
      print(mass_p)
      
      ggsave(paste0("vignettes/Case Studies/CaseData/Mass_plot_", scale,  "_", date, "_", runs, "runs.png"), plot=mass_p)
    }
  }
} else if(type == "DPMFA"){
  for(name in solved_df_names){
    
  }
}
```

```{r Make concentration plots}
if(type == "PMFA"){
  for(name in concentration_df_names){
    solution_name <- name
    
    Solution <- get(solution_name) |>
      mutate(RUN = as.integer(RUN)) |>
      mutate(Concentration = as.double(Concentration)) 
    
    source <- str_remove(solution_name, "concentration_ss_") |> 
          str_replace("_[^_]*$", "") |>  # Removes everything after the last underscore
          str_replace_all("_", " ")      # Replaces all underscores with spaces
    
    pol <- str_extract(solution_name, "(?<=_)[^_]*$")
    
    subt <- paste0(source, ", ", pol, ", ", y)
    
    # Aggregate plot data for all species
    Plot_data_agg <- Solution |>
      group_by(Scale, SubCompart, RUN, Unit) |>
      summarise(Concentration = sum(Concentration)) 
      
    scales <- unique(Plot_data_agg$Scale)
    
    # Make plots for each scale
    for (scale in scales) {
      plot_data_scale <- Plot_data_agg |>
        filter(Scale == scale) |>
        mutate(concname = paste0(SubCompart, " (", Unit, ")"))
      
      # Filter out the compartments without mass
      masscomps <- plot_data_scale |>
        filter(RUN == 1) |>
        filter(Concentration != 0)
      
      masscomps <- masscomps$SubCompart
      
      plot_data_scale <- plot_data_scale |>
        filter(SubCompart %in% masscomps) 
      
      if(source == "Tyre wear"){
        plot_data_scale <- plot_data_scale |>
          mutate(SubCompart = case_when(
            SubCompart == "othersoil" ~ "roadsidesoil",
            TRUE ~ SubCompart
          ))
      }
      
      # Concentration plot
      conc_p <- ggplot(plot_data_scale, mapping = aes(x = concname, y = Concentration, fill = concname)) +  
        geom_violin() +
        labs(title = paste0("Concentrations at ", scale, " scale"),
             subtitle = subt,
             x = "Compartment",
             y = "Concentration") +
        plot_theme +
        scale_y_continuous(trans = 'log10') +
        scale_fill_viridis_d() +
        theme(axis.text.x = element_blank(),  
              legend.position = "bottom") +   
        guides(fill = guide_legend(title = NULL))  + 
      scale_y_log10(  # Apply logarithmic scale
      # Major breaks at powers of 10
      breaks = scales::trans_breaks("log10", function(x) 10^x),
      
      # Labels in human-readable form
      labels = scales::trans_format("log10", scales::math_format(10^.x)),
    ) 
      
      print(conc_p)
      
      ggsave(paste0("vignettes/Case Studies/CaseData/Concentration_plot_", scale, "_", date, "_", runs, "runs.png"), plot=conc_p)
    }
  }
} else if(type == "DPMFA"){
  for(name in solved_df_names){
    
  }
}

```
