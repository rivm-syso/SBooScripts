---
title: "Trapped solver"
author: "Valerie de Rijk"
date: "`r Sys.Date()`"
output: github_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::knit_meta()
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE)
projectRoot <- paste(getwd(), "..", "..", sep = "/")
knitr::opts_knit$set(root.dir = projectRoot) 
```


This vignette demonstrates how to use the SimpleBox model in a trapped manner, allowing for the fate prediction of multi-faceted particles. In this vignette, we'll take a closer look at GO-Chitosan, a combination of the sheet-like graphene oxide and the biological compound Chitosan. 

## Initiation

We assume you have the input data for a substance or material of interest and all the data describing the SimpleBox world to be created ready and thus can run the initWorld script.

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
library(dplyr)
substance <-  "GO-Chitosan"
source("baseScripts/initWorld_onlyParticulate.R")

```

## Computing Spherical equivalent diameter

We calculate the spherical equivalent diameter (deq) and subsequently use it to overwrite radS. In this manner we include the shape of the considered particles. We update the matrix in the chunk after. [TODO: In future this could be included in the initialization for relevant particles that consist of multiple components]

We need the following properties for the GO-Chitosan related particles:

-   Shape

-   Size

-   Density

-   Other 'unknown' variables, such as attachment efficiency, etc.

| Property             | GO-Chitosan     | GO              | Chitoson         |
|----------------------|-----------------|-----------------|------------------|
| Shape                | Sheet-like      | Flake           | Fragment         |
| Size - square (LxB)  | 70 - 90 (80) um | 70 - 90 (80) um | 100-200 (150) nm |
| Size - thickness (H) | 10-20 (15) nm   | 1-10 (5) nm     | 100-200 (150) nm |
| Density              | Calculated      | 0.35 g/ml       | 0.874 g/ml       |

: The density of GO-chitosan is approximated by 1/8 \* dens_Graphene + 7/8 \* dens_Chitosan

```{r Computing Radius, message=FALSE, warning=FALSE}

# Longest <- World$fetchData("Longest_side")
# Intermediate <- World$fetchData("Intermediate_side")
# Shortest <- World$fetchData("Shortest_side")
Longest <- 80*1e-06
Intermediate <- 80*1e-06
Shortest <- 15*1e-9

Volume <- Longest*Intermediate*Shortest
d_eq <- ( 6/ pi * Volume)^(1/3)
rad_eq <- d_eq/2
print(rad_eq)

World$SetConst(RadS = rad_eq)


World$fetchData("RhoS")
World$UpdateKaas(mergeExisting = F)
```

## Adjusting Parameters with Uncertainty

Since attachment efficiencies (alpha) are very uncertain, below is a chunk where we can create distributions for these parameters. We start however with a deterministic calculation using averages.

```{r Example Uncertain Alpha, message=FALSE, warning=FALSE}
fwa_min <- 1e-4
fwa_max<- 0.1
n <- 100000
log_uniform_samples <- 10^runif(n, min = log10(fwa_min), max = log10(fwa_max))
fw_alpha_mean_log_samples <- mean(log_uniform_samples)


#Check with histogram 
hist(log_uniform_samples, breaks = 30, freq = FALSE,
     main = "Histogram of Log Uniform Distribution [10^-3, 10^-1]",
     xlab = "Value", ylab = "Density")
# Plot the probability density function (pdf) curve
curve(dunif(log10(x), min = log10(fwa_min), max = log10(fwa_max)) / x,
      from = fwa_min, to = fwa_max, add = TRUE, col = "blue", lwd = 2 )

#marine 
ma_min <- 1e-3 
ma_max <- 1
log_uniform_samples <- 10^runif(n, min = log10(ma_min), max = log10(ma_max))
marine_alpha_mean_log_samples <- mean(log_uniform_samples)


subcompartsmarine <- c("sea", "marinesediment", "freshwatersediment", "deepocean")


subcomparts <- c("river", "lake", "water", "agriculturalsoil", "naturalsoil", "othersoil")
all_subcomparts <- c(subcomparts, subcompartsmarine)
#species <- rep(c("Large", "Small"), times = length(all_subcomparts))

alpha = data.frame(
SubCompart = c(subcomparts,subcompartsmarine),  
alpha = c(fw_alpha_mean_log_samples, marine_alpha_mean_log_samples))

World$fetchData("alpha")
ToPaste <- lapply(list(alpha), function(x) {
  varName <- names(x)[!names(x) %in% The3D]
  stopifnot(length(varName)==1)
  # one line with 2 disadvantages of tidyverse..:
  as.data.frame(pivot_longer(data = x, cols = all_of(varName), names_to = "varName", values_to = "Waarde"))
})

dfs <- do.call(bind_rows, ToPaste)

World$mutateVars(dfs)

World$UpdateKaas(mergeExisting = F)
World$fetchData("alpha")
```

## NewSolver

Different solvers are available, basically:

1.  Solving the steadystate of the SimpleBox world

2.  Solving in time the states of SimpleBox world

Both will be illustrated bellow, but it starts with defining the solver you want to use by `world$NewSolver("[name of s_function]")`

### SBsteady

Currently there are two ways to solve the matrix in steady state, so with constant emission and infinite time horizon. These are:

1.  `SB1solve` - using solve from base R

2.  `SBsteady` - using runsteady from the rootSolve package

Another option would be to set a time horizon using the ode solver from the DeSolve package. This can be done using `SBsolve`.

```{r SBsteady}
# World$NewSolver("SBsteady")
# SB1Solve provides the best results, this uses the solve function in R.
World$NewSolver("SB1Solve") 

```

What solving means is that using matrix algebra a set of differential equations is solved:

`K %*% m + e`

Where:

K is the matrix of rate constants for each process describing the mass transfers to and from and out of a state (e.g. substance in freshwater (w1U) or small heteroagglomerate in natural soil (s1A)).

m is the mass in each compartment, e.g. 0 at t=0.

e is the emission to each compartment per unit of time, e.g. 1 t/y.

Here, we define the emissions for a Steady State Calculation, based on averages for 2035 for GO-Chitosan. We convert the emissions to kg/s

```{r constant emission}
emissions <- data.frame(Abbr = c("aCS", "s2CS", "w1CS"), 
                        Emis = c(0.000047, 150, 43))
emissions$Emis<- emissions$Emis * 1000 / (365.25 * 24 * 60 * 60)


# TODO: explain what is the reason for this Abbr? Why is it not a relational table defining scale, compartment and species as for all other data?
```

Now we are ready to run the solver, which results in the mass in each compartment.

```{r}
Solution <- World$Solve(emissions)
Solution <- Solution |>
  filter(Species != "Unbound")
#Solution <- World$SolutionAsRelational(Solution)
```
## Dynamic solving

### Adjusting Parameters to Match considered Scale

In this case study we are considering emission data only for Europe. By default the 'World' is represented by a nested regional scale, which is not relevant for the current assessment using emissions data only for Europe. Here we use the option to allocate part of the emissions to the regional scale based on the fraction of surface area in order to mimic not having a nested scale. In future one would be interested for instance in including a local or national scale as well. One could adjust the regional scale for this purpose.

The code is commented out, but this is an example of adjusting the regional scale to represent Switzerland. You can only adjust parameters that are initial input data, not variables that are calculated later in SBOO. The adjusted dataframes are printed below. Note, at this point the input is already converted to SI units, so new data also needs to be put in this format.

```{r Scaling, include=FALSE}

Area <- World$fetchData("TotalArea")
AreaRegional <- Area$TotalArea[Area$Scale =="Regional"]
AreaContinental <- Area$TotalArea[Area$Scale =="Continental"]
fracReg <- AreaRegional/AreaContinental
fracCont <- 1-fracReg

FracRC <- tibble(
  Scale_SBname = c("Regional","Continental"),
  Abr_scale = c("R","C"),
  AreaFraction = c(fracReg,fracCont)
)


print(FracRC)

```

We can also solve the differential equations dynamically in time, but the optimal implementation is still work in progress, see [issue](https://github.com/rivm-syso/SBoo/issues/111).

```{r emission data, include=FALSE}
file_paths <- 
  list.files("data/emissions",recursive = TRUE)
Emissions <-
  read_csv(paste0("data/emissions/",file_paths), id="file_name", col_names = c("RUN",0:24),skip = 1) # unit: Metric tonnes


```

### Prepare DPMFA data

Data from an DPMFA model should be prepared to fit the SBoo world. For instance the time unit should be correct, the mass unit is not as important as this will be the same in the output then, but for good measure we use kg. This is the quick and dirty way, a more elegant way is till in progress as mentioned above.

We define the compartments of the emission based on the DMPFA model.

*NOTE* all concentrations need to be in mass unit/s in order for the solver to work. This is due to the fact that the matrix operates in seconds

```{r Emissions, include=FALSE}
# TODO: solve for every RUN
Emissions <- 
  Emissions |>
  pivot_longer(
    cols = !c(file_name,RUN),
    names_to = "year",
    values_to = "emission_t" ) |> mutate_at('year',as.numeric) |> 
  ungroup() |> 
  group_by(file_name,year) |> 
  summarise(Emission_p50_kg = quantile(emission_t,probs = 0.5)*1000/(365.25*24*3600),
            Emission_mean_kg = mean(emission_t)*1000/(365.25*24*3600)) |> ungroup()

Emissions <- 
  Emissions |> 
  mutate(compartment = 
           case_when(str_detect(file_name, "(?i)Air") ~ "Air",
                     str_detect(file_name, "(?i)Soil") ~ "SludgeTreatedSoil",
                     str_detect(file_name, "(?i)Water") ~ "SurfaceWater",
                     str_detect(file_name, "(?i)Subsurface") ~ "Subsurface",
                     TRUE ~ "Other"),
         scale = 
           case_when(str_detect(file_name, "(?i)EU") ~ "EU_average",
                     str_detect(file_name, "(?i)Ireland") ~ "EU_STsoil",
                     str_detect(file_name, "(?i)Switzerland") ~ "EU_noSTsoil",
                     TRUE ~ "Other"),
         Substance = "GO-Chitosan",
  )

```

### Scaling Emission data based on material density

When running for only GO or only Chitosan, you want to correct for the fact that it's partly Chitosan and partly GO through using the densities.

```{r DensityScaling, include=FALSE}

Weightfactor <- switch(substance,
                       "GO-Chitosan" = 1,
                       "Chitosan" = 7/8,
                       "GO" = 1/8)

Emissions <-
  Emissions |> mutate(Emission_mean_kg = Emission_mean_kg* Weightfactor,
                      Emission_p50_kg = Emission_p50_kg*Weightfactor)

head(Emissions)

```

### Scaling Input Data based on World (Regional nested in Continental)

In this chunk, we adjust for the fact that the input data for the DMPFA model is all Europe based. Hence we scale by the factor fracReg and fracCont to still include the current regional scale (could alse be done differently). The regional data is thus a portion of the EU emission, scaled based on the land surface area.

```{r ScaleScaling, include=FALSE}

SBEmissions2 <- 
  Emissions |> mutate(
    Abr_comp =  case_match(compartment,
                           "Air" ~ "a",
                           "SludgeTreatedSoil" ~ "s2",
                           "SurfaceWater" ~ "w1",
                           .default = NA
    ),
    Abr_scale =  case_match(scale,
                            "EU_average" ~ "C",
                            .default = NA
    ),
    Abr_species = "S"
    
  ) |> drop_na() 

SBEmissions2 <-  
  SBEmissions2 |> rbind(
    SBEmissions2 |> 
      mutate(
        Abr_scale =  case_match(Abr_scale,
                                "C" ~ "R",
                                .default = NA
        ),
        scale = "EU_average"
      )
  ) |> full_join(FracRC) |> 
  
  mutate(Abr = paste0(Abr_comp,Abr_scale,Abr_species)) |> 
  mutate(Emission_mean_kg = Emission_mean_kg*AreaFraction,
         Emission_p50_kg = Emission_p50_kg*AreaFraction)

head(SBEmissions2)

```

### make time dependent emission functions

```{r approxfuns, include=FALSE}
SBEmissions3 <- 
  SBEmissions2 |> 
  mutate(time_s = year*(365.25*24*60*60)+(365.25*24*60*60)) |> ungroup() |> 
  group_by(compartment,Abr_scale,Abr,Substance) |> 
  summarise(n=n(),
            EmisFun = list(
              approxfun(
                data.frame(time_s = c(0,time_s), 
                           emis_kg=c(0,Emission_mean_kg)),
                rule = 1:1)
            )
  )

funlist <- SBEmissions3$EmisFun
names(funlist) <- SBEmissions3$Abr

times <- seq(0, 25*365.25*24*3600, by = 10000)

CompartInterest <- "s2CS"

time_s = c(0,(SBEmissions2 |> filter(Abr == CompartInterest) |> pull(year))*(365.25*24*60*60)+(365.25*24*60*60))
emis_kg = c(0,(SBEmissions2 |> filter(Abr == CompartInterest) |> pull(Emission_mean_kg)))

PlotEmisFun = funlist[[CompartInterest]]

plot(time_s,
     emis_kg)
curve(PlotEmisFun,
      add = TRUE)



```

### Dynamic solving for deterministic input data

The chunk below gives the opportunity to Solve for constant input data. The chunk after that gives the opportunity to also vary SB Input data

```{r DynamicSolve, include=FALSE}

##ODE

SimpleBoxODE = function(t, m, parms) {
  
  with(as.list(c(parms, m)), {
    e <- c(rep(0, length(SBNames)))
    
    for (name in names(funlist)) {
      e[grep(name, SBNames)] <- funlist[[name]](t)
    }
    
    dm <- K%*% m + e
    res <- c(dm)
    list(res, signal = e)
  })
}

# print(SBNames)

#Function to Solve
SBsolve4 <- function( tmax = 1e10, nTIMES = 100, Engine, funlist) {
  
  SB.K = Engine
  SBNames = colnames(Engine)
  SB.m0 <- rep(0, length(SBNames))
  SBtime <- seq(0,tmax,length.out = nTIMES)
  
  
  out <- deSolve::ode(
    y = as.numeric(SB.m0),
    times = SBtime ,
    func = SimpleBoxODE,
    parms = list(K = SB.K, SBNames=SBNames, funlist=funlist),
    rtol = 1e-10, atol = 1e-2)
  #if(as.character(class(deS)[1])!="data.frame") return (list(errorstate="error", deS))
  colnames(out)[1:length(SBNames)+1] <- SBNames
  colnames(out)[grep("signal",colnames(out))] <- paste("emis",SBNames,sep = "2")
  as.data.frame(out)
  
}



# Solving
Solution <- SBsolve4(tmax = 24*(365.25*24*3600),
nTIMES = 130,
Engine = World$exportEngineR(),
funlist = funlist)

# Solution <- SBsolve4(tmax = 25*(365.25*24*3600), 
#                      nTIMES = 130,
#                      Engine = as.matrix(K.Matrix),
#                      funlist = funlist)

Solution <- as.data.frame(Solution)

# Same plot of emission as above
plot(Solution$time,Solution$emis2s2CS)

plot(Solution$time,Solution$w1CS)

plot(Solution$time,Solution$s2CS)
plot(Solution$time,Solution$s2CA)
plot(Solution$time,Solution$s2CP)

plot(Solution$time,Solution$aCS)



```

To be able to solve for seperate GO or Chitosan, we need to obtain the fluxes representing the removal processes. We first need to use the engine to get the processes (k) from and to each compartment with usable abbreviations. 
```{r getting fluxes/prepping kaas}
World$kaas
kaas <- as_tibble(World$kaas)
# Define acronyms maps
accronym_map <- c("marinesediment" = "sd2",
                "freshwatersediment" = "sd1",
                "lakesediment" = "sd0", #SB Excel does not have this compartment. To do: can we turn this off (exclude this compartment) for testing?
                "agriculturalsoil" = "s2",
                "naturalsoil" = "s1",
                "othersoil" = "s3",
                "air" = "a",
                "deepocean" = "w3",
                "sea" = "w2",
                "river" = "w1",
                "lake" = "w0", 
                "cloudwater" = "cw")

accronym_map2 <- c("Arctic" = "A",
                   "Moderate" = "M",
                   "Tropic" = "T",
                   "Continental" = "C",
                   "Regional" = "R")

accronym_map3 <- c("Dissolved" = "D", 
                   "Gas" = "G", 
                   "Large" = "P", 
                   "Small" = "A",
                   "Solid" = "S", 
                   "Unbound" = "U")

kaas <- kaas |> mutate(from =  paste0(accronym_map[fromSubCompart], 
                            accronym_map2[fromScale], 
                            accronym_map3[fromSpecies]),
               to = paste0(accronym_map[toSubCompart], 
                           accronym_map2[toScale], 
                           accronym_map3[toSpecies]))




```

```{r}
solution_transposed <- t(Solution)
colnames(solution_transposed) <- solution_transposed[1, ]
# Remove the first row as it's now the column names
solution_transposed <- solution_transposed[-1, ]

```