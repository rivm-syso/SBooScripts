---
title: "Solver script"
author: "Valerie de Rijk, Joris Quik, Jaap Slootweg"
date: "`r Sys.Date()`"
output: github_document
editor_options: 
  chunk_output_type: console
---

## *Initiation*

*We assume you have the input data for a substance or material of interest and all the data describing the SimpleBox world to be created ready and thus can run the initWorld script.*

```{r}
library(dplyr)
substance <-  "GO-Chitosan"
source("baseScripts/initWorld_onlyParticulate.R")
World$fetchData("RhoS")
World$fetchData("RadS")
```

## *Adjusting Parameters to Match considered Scale*

In this case study we are considering emission data for Switzerland and Europe. As such, we need to adjust the World to represent this country and continent. Since Europe is the default for the continental scale, adjustments here are not necessary. The data below adjust the Regional Scale to represent Switzerland. You can only adjust parameters that are initial input data, not variables that are calculated later in SBOO.The adjusted dataframes are printed below. Note, at this point the input is already converted to SI units, so new data also needs to be put in this format. 

```{r}
# 
# LandFRAC <- data.frame(
#   Scale = "Regional",
#   SubCompart = c("agriculturalsoil", "lake", "naturalsoil", "othersoil" , "river"), 
#   landFRAC = c(0.37, 0.02, 0.51, 0.08, 0.02)
# )
# # TotalArea <- data.frame(
# #   Scale = c("Arctic", "Continental", "Moderate", "Regional"),
# #   TotalArea = c(4.25E+13, 7.43E+12, 8.50E+13, 4.13e+11)
# # )
# 
# Temperature <- data.frame(
#   Scale = "Regional", 
#   Temp = 279
# )
# 
# RAINrate <- data.frame(
#   Scale = "Arctic",
#   RAINrate = 4.37e-5
# )
# 
# ParamToAdjust <- list(LandFRAC, Temperature, RAINrate)
# for (i in seq_along(ParamToAdjust)) {
#   ParamToAdjust[[i]] <- World$mutateVar(ParamToAdjust[[i]])
# }
# print(ParamToAdjust)

## scaling of world 

Area <- World$fetchData("TotalArea")
AreaRegional <- Area$TotalArea[Area$Scale =="Regional"]
AreaContinental <- Area$TotalArea[Area$Scale =="Continental"]
fracReg <- AreaRegional/AreaContinental
fracCont <- 1-fracReg
print(fracReg)
print(fracCont)
```


## *NewSolver*

*Different solvers are available, basically:*

1.  *Solving the steadystate of the SimpleBox world*

2.  *Solving in time the states of SimpleBox world*

*Both will be illustrated bellow, but it starts with defining the solver you want to use by `world$NewSolver("[name of s_function]")`*

### *SBsteady*

```{r SBsteady}
World$NewSolver("SBsteady")
```

*What solving means is that using matrix algebra a set of differential equations is solved:*

*`K %*% m + e`*

*Where:*

*K is the matrix of rate constants for each process describing the mass transfers to and from and out of a state (e.g. substance in freshwater (w1U) or small heteroagglomerate in natural soil (s1A)).*

*m is the mass in each compartment, e.g. 0 at t=0.*

*e is the emission to each compartment per unit of time, e.g. 1 t/y.*

*To solve this set of differential equations we thus need an emission, e.g. 1 ton/year to air. The height of this emission is not*

```{r constant emission}
emissions <- data.frame(Abbr = "aCS", Emis = 1000/(365.25*24*60*60)) # convert 1 t/y to si units: kg/s

# TODO: explain what is the reason for this Abbr? Why is it not a relational table defining scale, compartment and species as for all other data?
```

*Now er are ready to run the solver, which results in the mass in each compartment.*

```{r}
World$Solve(emissions)
```

## *SBdynamic*

*It is possible to solve the differential equations dynamicallly in time, but the optimal implementation is still work in progress.*

```{r}
file_paths <- 
  list.files("/rivm/n/rijkdv/testing_simplebox/emissions/",recursive = TRUE)



```

### *Prepare DPMFA data*

*Data from an DPMFA model should be prepared to fit the SBoo world. For instance the time unit should be correct, the mass unit is not as important as this will be the same in the output then, but for good measure we use kg.* This is the quick and dirty way, a more elegant way is till in progress.

We define the compartments of the emission based on the DMPFA model. 

```{r Emissions}
file_paths <- 
  list.files("/rivm/n/rijkdv/testing_simplebox/emissions/",recursive = TRUE)
Emissions <-
  read_csv(paste0("/rivm/n/rijkdv/testing_simplebox/emissions/",file_paths), id="file_name", col_names = c("RUN",0:24),skip = 1) # unit: Metric tonnes

# TODO: solve for every RUN
Emissions <- 
  Emissions |>
  pivot_longer(
    cols = !c(file_name,RUN),
    names_to = "year",
    values_to = "emission_t" ) |> mutate_at('year',as.numeric) |> 
  ungroup() |> 
  group_by(file_name,year) |> 
  summarise(Emission_p50_kg = quantile(emission_t,probs = 0.5)*1000,
            Emission_mean_kg = mean(emission_t)*1000) |> ungroup()

Emissions <- 
  Emissions |> 
  mutate(compartment = 
           case_when(str_detect(file_name, "(?i)Air") ~ "Air",
                     str_detect(file_name, "(?i)Soil") ~ "SludgeTreatedSoil",
                     str_detect(file_name, "(?i)Water") ~ "SurfaceWater",
                     str_detect(file_name, "(?i)Subsurface") ~ "Subsurface",
                     TRUE ~ "Other"),
         scale = 
           case_when(str_detect(file_name, "(?i)EU") ~ "EU",
                     str_detect(file_name, "(?i)Ireland") ~ "Ireland",
                     str_detect(file_name, "(?i)Switzerland") ~ "Switzerland",
                     TRUE ~ "Other"),
         Substance = "GO-Chitosan",
  )

```
In this chunk, we adjust for the fact that the input data for the DMPFA model is all Europe based. Hence we scale by the factor fracReg and fracCont to ensure we do not overestimate input. The regional data is thus overwritten by the function EmissionContinental*FracReg

```{r}

SBEmissions2 <- 
  Emissions |> mutate(
    Abr_comp =  case_match(compartment,
                           "Air" ~ "a",
                           "SludgeTreatedSoil" ~ "s2",
                           "SurfaceWater" ~ "w1",
                           .default = NA
    ),
    Abr_scale =  case_match(scale,
                            "EU" ~ "C",
                            "Switzerland" ~ "R",
                            .default = NA
    ),
    Abr_species = "S"
    
  ) |> drop_na() |>  mutate(Abr = paste0(Abr_comp,Abr_scale,Abr_species))

update_emission <- function(SBEmissions2, cs_abr, rs_abr) {
  cs_values <- SBEmissions2 |>
    filter(Abr == cs_abr) |>
    select(year, Emission_mean_kg)
  
  SBEmissions2 <- SBEmissions2 |>
    left_join(cs_values, by = "year", suffix = c("", paste0("_", cs_abr))) |>
    mutate(Emission_mean_kg = ifelse(Abr == rs_abr, get(paste0("Emission_mean_kg_", cs_abr)) * fracReg, Emission_mean_kg)) |>
    select(-matches(paste0("Emission_mean_kg_", cs_abr)))
  SBEmissions2 <- SBEmissions2 |>
  mutate(Emission_mean_kg = ifelse(Abr == cs_abr, Emission_mean_kg * fracCont, Emission_mean_kg))
  
  return(SBEmissions2)
  
  
}

# Update Emission_mean_kg for all specified pairs of compartments
compartment_pairs <- list(c("aCS", "aRS"), c("s2CS", "s2RS"), c("w1CS", "w1RS"))

for (pair in compartment_pairs) {
  SBEmissions2 <- update_emission(SBEmissions2, pair[1], pair[2])
}

SBEmissions2 <- 
  SBEmissions2 |> 
  mutate(time_s = year*(365.25*24*60*60)+(365.25*24*60*60)) |> 
  group_by(compartment,scale,Substance) |> 
  summarise(n=n(),
            EmisFun = list(approxfun(
              data.frame(time_s = c(0,time_s), emis_kg=c(0,Emission_mean_kg)),rule = 1:1)))

# EmisFun with input in seconds and output in kg's going from 0 to 25 years in seconds.
SBEmissions2 <-
  SBEmissions2 |> mutate(
    Abr_comp =  case_match(compartment,
                           "Air" ~ "a",
                           "SludgeTreatedSoil" ~ "s2",
                           "SurfaceWater" ~ "w1",
                           .default = NA
    ),
    Abr_scale =  case_match(scale,
                            "EU" ~ "C",
                            "Switzerland" ~ "R",
                            .default = NA
    ),
    Abr_species = "S"
    
  ) |> drop_na() |>  mutate(Abr = paste0(Abr_comp,Abr_scale,Abr_species))
  funlist <- SBEmissions2$EmisFun
  names(funlist) <- SBEmissions2$Abr
  
times <- seq(0, 25*365.25*24*3600, by = 10000)

# Create a data frame to store the results
results <- data.frame(Time = times)

# Apply each function to the times and store the results
for (name in names(funlist)) {
  func <- funlist[[name]]
  results[[name]] <- sapply(times, func)
}

# Convert the data frame to long format for ggplot2
results_long <- results |>
  pivot_longer(-Time, names_to = "Compartment", values_to = "Value")

# Plot the results
ggplot(results_long, aes(x = Time, y = Value, color = Compartment)) +
  geom_line() +
  labs(title = "Function Results Over Time",
       x = "Time (seconds)",
       y = "Function Value") +
  theme_minimal()


```

Here, the chunk is where you would potentially have input data from both regional and continental scale. 
```{r}
Emissions <-
  Emissions |> 
  # Emission in year 0 is the cumulative that is actually added up to the last second of the first year (so at time point (365.25*24*60*60)) at time 0 emission is 0.
  mutate(time_s = year*(365.25*24*60*60)+(365.25*24*60*60)) |> 
  group_by(compartment,scale,Substance) |> 
  summarise(n=n(),
            EmisFun = list(approxfun(
              data.frame(time_s = c(0,time_s), emis_kg=c(0,Emission_mean_kg)),rule = 1:1)))



# Assuming EmisFun is a list of functions indexed by compartment names


### filter and name the emissions that we actually have states for: 
### needs manual tweaking for correct matching
SBemissions <-
  Emissions |> mutate(
    Abr_comp =  case_match(compartment,
                           "Air" ~ "a",
                           "SludgeTreatedSoil" ~ "s2",
                           "SurfaceWater" ~ "w1",
                           .default = NA
    ),
    Abr_scale =  case_match(scale,
                            "EU" ~ "C",
                            "Switzerland" ~ "R",
                            .default = NA
    ),
    Abr_species = "S"
    
  ) |> drop_na() |>  mutate(Abr = paste0(Abr_comp,Abr_scale,Abr_species))

  funlist <- SBemissions$EmisFun
  names(funlist) <- SBemissions$Abr
  
funlist <- SBemissions$EmisFun
names(funlist) <- SBemissions$Abr

# Generate the sequence of times (from 0 to 1 year in seconds)
times <- seq(0, 25*365.25*24*3600, by = 10000)

# Create a data frame to store the results
results <- data.frame(Time = times)

# Apply each function to the times and store the results
for (name in names(funlist)) {
  func <- funlist[[name]]
  results[[name]] <- sapply(times, func)
}

# Convert the data frame to long format for ggplot2
results_long <- results |>
  pivot_longer(-Time, names_to = "Compartment", values_to = "Value")

# Plot the results
ggplot(results_long, aes(x = Time, y = Value, color = Compartment)) +
  geom_line() +
  labs(title = "Function Results Over Time",
       x = "Time (seconds)",
       y = "Function Value") +
  theme_minimal()

```
## Solving for constant input data

The chunk below gives the opportunity to Solve for constant input data. The chunk after that gives the opportunity to also vary SB Input data

```{r, eval=FALSE}

Engine <-World$exportEngineR()
interpolations <- funlist
##ODE
SimpleBoxODE = function(t, m, parms) {
  
  with(as.list(c(parms, m)), {
    e <- c(rep(0, length(SBNames)))
    for (name in names(interpolations)) {
      e[grep(name, SBNames)] <- interpolations[[name]](t)
    }
    dm <- K%*% m + e
    res <- c(dm)
    list(res, signal = e)
  })
}
SBNames <-colnames(Engine)
print(SBNames)
SB.m0 <- rep(0, length(SBNames))

#Function to Solve
SBsolve4 <- function( tmax = 1e10, nTIMES = 100) {
  
  SB.K <- Engine
  
  SBtime <- seq(0,tmax,length.out = nTIMES)
  
  
  out <- deSolve::ode(
    y = as.numeric(SB.m0),
    times = SBtime ,
    func = SimpleBoxODE,
    parms = list(K = SB.K, SBNames, interpolations),
    rtol = 1e-10, atol = 1e-2)
  #if(as.character(class(deS)[1])!="data.frame") return (list(errorstate="error", deS))
  
}
#Solving
Solution<- SBsolve4(tmax = 25*(365.25*24*3600), nTIMES = 130)
```

## Varying Input Data

This is still work in progress. To try multiple definitions of input parameters, you currently have to extract the calculation engine from the R6 core with different input.This chunk gives the possibility to solve engines for (combinations of) varing particles and solve for the varying input data with the code chunck below that.
In this chunk, a check for the module k_Sedimentation is implemented as a check for dependency on particle size.
```{r}
particle_sizes <- seq(from = 50e-6, to = 90e-6, length.out = 10)
#Generation of matrix 
result_engine <- list()
result_sedimentation <- list()


#function for getting engines
run_particle_simulation <- function(particle_sizes, emissions) {
  # Function to run simulation for a single particle size
  run_simulation <- function(size) {
    print(paste("Running simulation for particle size:", size))
    World$SetConst(RadS = size)
    World$UpdateKaas(mergeExisting = FALSE)
    
    sedimentation <- World$moduleList[["k_Sedimentation"]]$execute()
    sedimentation$particle_size <- size
    
    World$NewSolver("SBsteady")
    World$Solve(emissions)
    Engine <- World$exportEngineR()
    
    result <- list(
      engine_result = Engine,
      sedimentation_result = sedimentation
    )
    
    return(result)
  }
  
  # Use lapply to iterate over particle sizes
  results <- suppressWarnings(lapply(particle_sizes, run_simulation))
  
  # Split results into separate lists for engine and sedimentation
  result_engine <- lapply(results, function(res) res$engine_result)
  result_sedimentation <- lapply(results, function(res) res$sedimentation_result)
  
  # Return results as a list
  return(list(
    engine_results = result_engine,
    sedimentation_results = result_sedimentation
  ))
}

# Call the function
simulation_results <- run_particle_simulation(particle_sizes, emissions)
sedimentation_results <- simulation_results$sedimentation_results
engine_results <- simulation_results$engine_results
 
```

## Solver Module

```{r Solver}
SimpleBoxODE = function(t, m, parms) {
  
  with(as.list(c(parms, m)), {
    e <- c(rep(0, length(SBNames)))
    for (name in names(interpolations)) {
      e[grep(name, SBNames)] <- interpolations[[name]](t)
    }
    dm <- K%*% m + e
    res <- c(dm)
    list(res, signal = e)
  })
}

# exporting Engine
Engine_1 <- engine_results[[1]]
SBNames <-colnames(Engine_1)
print(SBNames)
print(SBNames)
SB.m0 <- rep(0, length(SBNames))
print(length(SB.m0))
interpolations <-funlist
SBsolve4 <- function(tmax = 1e10, nTIMES = 100, Engine) {
  
  SB.K <- Engine
  
  SBtime <- seq(0, tmax, length.out = nTIMES)
  
  out <- deSolve::ode(
    y = as.numeric(SB.m0),
    times = SBtime,
    func = SimpleBoxODE,
    parms = list(K = SB.K, SBNames, interpolations),
    rtol = 1e-10, atol = 1e-2
  )
  
  return(out)
}

# Initialize a list to store the solutions
Solutions <- list()

# Loop through each Engine and solve
for (i in seq_along(engine_results)) {
  print(i)
  Solution <- SBsolve4(tmax = 25 * (365.25 * 24 * 3600), nTIMES = 10, Engine = engine_results[[i]])
  Solutions[[i]] <- Solution
  rm(Solution)
}

```

## *Output Processing*

To move from the solution of the ODE solver to usable output data we need to split the output into corresponding mass data per compartment over time and emission signals over time. The first chunk is for one output, the latter chunk for varying input or emission data.

```{r Output Processing one solution, eval=False}
library(dplyr)
#for one Solution
Solution <- as.data.frame(Solution)
NamesK <- SBNames
print(NamesK)
print(length(NamesK))
colnames(Solution)[2:156] <- NamesK

#seperate signals and matrix
#compartments
compartments <- Solution[, 1:156]
compartments <- compartments |> select(-matches("U$"))
signals <- Solution[, 157:311]
colnames(signals) <- NamesK
signals_total <- data.frame(rowSums(signals))
signals_total$time <- Solution[, 1]

#Checks
#Emission over time
plot1 <-ggplot(signals_total, aes(x = time, y =rowSums.signals.)) +
  geom_line() +
  labs(title = "Emissions Over Time", x = "Time", y = "Emissions")

show(plot1)

#further data manipulation for the compartments
split_df <- function(df, solution_matrix) {
  # Extract the capital letters (A, R, C, T, M) in column names
  patterns <- unique(gsub("[^ARCTM]", "", colnames(df)))

  # Function to adjust the dataframe
  adjust_df <- function(df) {
    df$time <- compartments$time
    return(df)
  }

  # Split the dataframe based on the presence of specified capital letters using lapply
  split_dfs <- lapply(patterns, function(pattern) {
    cols <- grepl(pattern, colnames(df))
    adjusted_df <- df[, cols, drop = FALSE]
    adjust_df(adjusted_df)
  })

  # Assign names to the split dataframes
  names(split_dfs) <- patterns

  # Output the split dataframes
  invisible(lapply(names(split_dfs), function(pattern) {
    cat("Pattern:", pattern, "\n")
    print(split_dfs[[pattern]])
    cat("\n")
  }))

  return(split_dfs)
}

# Apply the function to split the dataframe
split_dfs <- split_df(compartments, solution_matrix)

# Assuming A, C, T, R, and M are the split dataframes
A <- split_dfs[["A"]]
C <- split_dfs[["C"]]
T <- split_dfs[["T"]]
R <- split_dfs[["R"]]
M <- split_dfs[["M"]]



#extra filtering for A
# Regular expression to match columns with "A" as the first capital letter after lowercase letters and numbers
pattern <- "^[a-z0-9]*A"

# Identify columns that do not match the pattern
columns_to_keep <- !grepl(pattern, names(A))

# Subset the dataframe to keep only the desired columns
A <- A[, !columns_to_keep]
A$time <- compartments$time

```

Output processing for multiple solutions.

```{r Output Processing }


NamesK <- SBNames
Solutions_all <- list()


# Define the function to split dataframes based on patterns
split_df <- function(df, compartments) {
  # Extract the capital letters (A, R, C, T, M) in column names
  patterns <- unique(gsub("[^ARCTM]", "", colnames(df)))
  
  # Function to adjust the dataframe
  adjust_df <- function(df) {
    df$time <- compartments$time
    return(df)
  }
  
  # Split the dataframe based on the presence of specified capital letters using lapply
  split_dfs <- lapply(patterns, function(pattern) {
    cols <- grepl(pattern, colnames(df))
    adjusted_df <- df[, cols, drop = FALSE]
    adjust_df(adjusted_df)
  })
  
  # Assign names to the split dataframes
  names(split_dfs) <- patterns
  
  return(split_dfs)
}

# Initialize a list to store the results)

# Loop through all solutions in the list
for (i in seq_along(Solutions)) {
  # Convert the current solution to a dataframe
  Solution <- as.data.frame(Solutions[[i]])
  
  # Set column names for the compartments and signals
  colnames(Solution)[2:156] <- NamesK
  
  # Separate signals and matrix compartments
  compartments <- Solution[, 1:156]
  compartments <- compartments %>% select(-matches("U$"))
  
  signals <- Solution[, 157:311]
  colnames(signals) <- NamesK
  signals_total <- data.frame(rowSums(signals))
  signals_total$time <- Solution[, 1]
  
  # Plot emissions over time
  plot1 <- ggplot(signals_total, aes(x = time, y = rowSums.signals.)) + 
    geom_line() +
    labs(title = "Emissions Over Time", x = "Time", y = "Emissions")
  
  print(plot1)  # Use print instead of show in scripts
  
  # Split the compartments dataframe
  split_dfs <- split_df(compartments, compartments)
  
  # Extract the individual split dataframes
  A <- split_dfs[["A"]]
  C <- split_dfs[["C"]]
  T <- split_dfs[["T"]]
  R <- split_dfs[["R"]]
  M <- split_dfs[["M"]]
  
  # Further filtering for A
  pattern <- "^[a-z0-9]*A"
  columns_to_keep <- !grepl(pattern, names(A))
  A <- A[, !columns_to_keep]
  A$time <- compartments$time

  
  # Save the results in the list with dynamic names
  Solutions_all[[paste0("Solution_", i)]] <- list(
    A = A,
    C = C,
    T = T,
    R = R,
    M = M
  )
}




```

## *Plotting of Output*

Below you can create a plot for one output, the chunk after that represents uncertainty based on multiple outputs.

```{r plotting}
# Define the plot_dataframe function
plot_dataframe <- function(df, title) {
  data_to_plot <- tidyr::gather(df, key = "variable", value = "value", -time)
  
  ggplot(data_to_plot, aes(x = time, y = value, color = variable)) +
    geom_line() +
    labs(title = title,
         x = "Time",
         y = "Value")
}

# Named list of dataframes
dataframes <- list(
  A = A,
  C = C,
  T = T,
  R = R,
  M = M
)

# Plot and print each dataframe
plots <- lapply(names(dataframes), function(name) {
  plot_dataframe(dataframes[[name]], name)
})

# Show the plots
for (plot in plots) {
  print(plot)
}

```

```{r output from all solutions}

## seperate dataframes 
# Loop through the Solutions_all list and plot each dataframe
for (i in seq_along(Solutions_all)) {
  solution <- Solutions_all[[i]]
  for (j in names(solution)) {
    plot <- plot_dataframe(solution[[j]], title = j)
    print(plot)
  }
}


# Initialize an empty list to store summary statistics per compartment
summary_stats_per_compartment <- list()

# Loop through each compartment (A, C, T, R, M)
for (compartment in c("A", "C", "T", "R", "M")) {
  compartment_data <- lapply(Solutions_all, function(solution) {
    # Extract the dataframe for the current compartment
    df <- solution[[compartment]]
    df$time <- as.character(df$time) # Ensure time column is character for consistency
    
    # Gather the data for easier processing
    df_gathered <- tidyr::gather(df, key = "variable", value = "value", -time)
    
    return(df_gathered)
  })
  
  # Combine data for all solutions and calculate mean and standard deviation
  combined_data <- bind_rows(compartment_data)
  summary_stats <- combined_data %>%
    group_by(time, variable) %>%
    summarize(mean_value = mean(value),
              sd_value = sd(value))
  
  # Add compartment information
  summary_stats$compartment <- compartment
  
  # Append to the summary_stats_per_compartment list
  summary_stats_per_compartment[[compartment]] <- summary_stats
}

# Combine all compartment summary statistics into one dataframe
summary_stats_final <- bind_rows(summary_stats_per_compartment)

summary_stats_C <- summary_stats_final %>%
  filter(compartment == "C")

# Plot for compartment A
ggplot(summary_stats_C, aes(x = as.numeric(time), y = mean_value, group = variable, color = variable)) +
  geom_line() +
  geom_ribbon(aes(ymin = mean_value - sd_value, ymax = mean_value + sd_value, fill = variable), alpha = 0.3) +
  labs(title = "Mass in compartment with Standard Deviation for Compartment C",
       x = "Time",
       y = "Mean Value")
       #color = "Variable").


# Create a list to store the plots
plots_list <- list()

# Iterate over compartments
for(compartment in unique(summary_stats_final$compartment)) {
  
  # Subset data for the current compartment
  summary_stats_compartment <- summary_stats_final %>%
    filter(compartment == compartment)
  
  # Get unique variables for the current compartment
  unique_variables <- unique(summary_stats_compartment$variable)
  
  # Create plot for the current compartment
  plot <- ggplot(summary_stats_compartment, aes(x = as.numeric(time), y = mean_value, group = variable, color = variable)) +
    geom_line(data = subset(summary_stats_compartment, variable %in% unique_variables)) +
    geom_ribbon(data = subset(summary_stats_compartment, variable %in% unique_variables), aes(ymin = mean_value - sd_value, ymax = mean_value + sd_value, fill = variable), alpha = 0.3) +
    labs(title = paste("Mass in compartment with Standard Deviation for", compartment),
         x = "Time",
         y = "Mean Value",
         color = "Variable",
         fill = "Variable")
  
  # Store the plot in the list
  plots_list[[compartment]] <- plot
}

# Print each plot
for (i in 1:length(plots_list)) {
  print(plots_list[[i]])
}



```
