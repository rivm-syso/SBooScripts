---
title: "Probabilistic use of SimpleBox"
author: "Anne Hids, Valerie de Rijk, Joris Quik, Jaap Slootweg"
date: "`r Sys.Date()`"
output: github_document
editor_options: 
  chunk_output_type: console
---

SimpleBox (SBoo) has specific solvers available that allow running the model deterministic or probabilistic. We assume you already understand the basics of using SimpleBox and have an idea of what input variables or emissions you want to input with a certain degree of uncertainty or variability. There are basically to types of solvers to use here:

1.  UncertainSolver for running the model n times calculating steady state output (mass/concentration)
2.  UncertainDynamicSolver for running the model n times calculating dynamic output

For both the world needs to be initialized first, in this case for only the Molecular species, and init the UncertainSolver.

```{r Initialize World, warning=FALSE, message=FALSE}

library(tidyverse)

source("baseScripts/initWorld_onlyMolec.R") # creates World

World$NewSolver("UncertainSolver")
```

## 1. Probabilistic Solver - Steady state

There are two ways to use the UncertainSolver:

1.  With uncertain variables and variable emissions.
2.  With uncertain variables but one set of emissions

Method 1 will be explained first, then method 2.

### 1.1 Uncertain variables and variable emissions case

#### Create tibble with samples for uncertain variables

The first step is to determine the independent uncertain variables, including emissions, and the number of runs. Each independent variable is sampled using latin hypercube sampling (lhs), which is efficient, but creates samples in the 0 - 1 range. Each variable needs a function to transpose the 0 - 1 sample to the proper range and distribution. We have a convenience method to help create for instance triangular functions.

```{r Define triangular distribution function, warning=FALSE, message=FALSE}
triangular_cdf_inv <- World$Make_inv_unif01(fun_type = "triangular", pars = list (a=0.5, b=1.5, c=1))
par(mfrow = c(1, 2))
curve(triangular_cdf_inv, from = 0, to = 1)
#check sampling 
hist(triangular_cdf_inv(runif(5000)), breaks = 40)
par(mfrow = c(1, 2))
```

##### Prepare variable samples

Now we are ready to prepare the variable data and define the min, max and peak value of the distribution for each variable.

In this example the following three variables are used:

1.  TODO
2.  TODO
3.  TODO

In the chunk below, the name, scale, subcompartment, min, max and peak value are defined for each variable, based on the values in the 'World'.

```{r Get min, max and peak value of variable values, warning=FALSE, message=FALSE}
# Define the names of the uncertain variables

Boxvars <- data.frame( # TODO? "waarde"
  varName = "kdeg",
  SubCompart = c("river", "air", "agriculturalsoil")
) |> World$fetch_current()


Boxvars <- Boxvars |>
  mutate(
    a = waarde*0.5,
    b = waarde*1.5) 

#Define funs
varFuns <- apply(Boxvars, 1, function(aRow){
  World$Make_inv_unif01("triangular", as.list(aRow[c("a", "b", "waarde")]))
})

```

##### Prepare emission data

In this example, we will take a steady state emission data frame as the starting point for creating the triangular distributions. You could also directly enter the min, max and peak values if you have them.

```{r Create steady state emission dataframe, warning=FALSE, message=FALSE}
# Create the steady state emission dataframe
emissions <- data.frame(Abbr = c("aRU", "s2RU", "w1RU"), Emis = c(10000, 10000, 10000)) # convert 1 t/y to si units: kg/s

MW <- World$fetchData("MW")

emissions <- emissions |>
  mutate(Emis = Emis*1000/(365*24*60*60)) 

```


Now that the emission data frame is made, we can scale the samples we took earlier to the triangular distribution just like we did for the variables.

```{r Scale the emissions to the distributions, warning=FALSE, message=FALSE}

emissions$a <- emissions$Emis * 0.7
emissions$b <- emissions$Emis * 1.3

emisFuns <- apply(rowwise(emissions) |> select(a, b, Emis), 1, function(therow){
  World$Make_inv_unif01("triangular", as.list(therow))
})

```


```{r Create samples, warning=FALSE, message=FALSE}
library(lhs)

n_vars <- length(varFuns) # The number of variables you want to create a distribution for
n_emiscomps <- length(emisFuns) # The number of compartments that have emissions
n_samples <- 100 # The number of samples you want to pull from the distributions for each variable

n_lhs <- n_vars + n_emiscomps # Total number of vectors to create with latin hypercube sampling (lhs)

lhs_samples <- optimumLHS(n_samples, n_lhs) # Generate numbers between 0 and 1 using lhs

# Separate the samples for the variable and emission distributions from each other:
lhs_samples_vars <- lhs_samples[, 1:n_vars] 
lhs_samples_emis <- lhs_samples[, (n_vars + 1):ncol(lhs_samples)]
```

If you think your variables are correlated you can use:
```{r}
# Define the desired correlation matrix
desired_correlation <- matrix(c(1, 0.8, 0.5,
                                0.8, 1, 0.3,
                                0.5, 0.3, 1), nrow = 3)

# Perform Cholesky decomposition on the desired correlation matrix
L <- chol(desired_correlation)

# Transform the LHS samples to have the desired correlation structure
correlated_samples <- lhs_samples_vars %*% L
#TODO now values are out of the 0-1 range! ????

```

#### Solve

The UncertainSolver is needed to apply simplebox probabilistically using a tibble with nested samples.

```{r Solve, warning=FALSE, message=FALSE}

solved <- World$Solve(emissions, lhsFuns, needdebug = F, sample_df)

```





Now this data needs to be combined into a tibble, and the function for the triangular distribution written earlier is applied to the tibble. The result is a nested tibble, containing the name, scale and subcompartment for each variable, and the sample data is nested.

```{r Scale the samples to the distributions, warning=FALSE, message=FALSE}
params <- tibble(
  varName = c(var1Name, var2Name, var3Name),
  Scale = c(var1$Scale, var2$Scale, var3$Scale),
  SubCompart = c(var1$SubCompart, var2$SubCompart, var3$SubCompart),
  data = list(
    tibble(id = c("a", "b", "c"), value = c(var1$a, var1$b, var1$c)),
    tibble(id = c("a", "b", "c"), value = c(var2$a, var2$b, var2$c)),
    tibble(id = c("a", "b", "c"), value = c(var3$a, var3$b, var3$c))
  )
)

sample_df <- params

# Transform each LHS sample column to the corresponding triangular distribution
for (i in 1:n_vars) {
  a <- filter(params$data[[i]], id == "a") %>% pull(value)
  b <- filter(params$data[[i]], id == "b") %>% pull(value)
  c <- filter(params$data[[i]], id == "c") %>% pull(value)
  
  samples <- triangular_cdf_inv(lhs_samples_vars[, i], a, b, c)
  
  # Create a new tibble for 'data' with samples replacing original values
  new_data <- tibble(value = samples)
  
  # Update the data column in the sample_df
  sample_df$data[[i]] <- new_data
}
```




# Make plots for every variable

```{r Data preparation for plots}
Input_Variables <- 
  solved$Input_Variables |> unnest(data) 
Input_Emission <- 
  solved$Input_Emission |> unnest(Emis) 

Plot_data <- 
  Input_Variables |> 
# some units missing resulting in NA
  pivot_wider(names_from = c(varName,Scale,SubCompart,Unit), values_from = value) |> 
  full_join(solved$SteadyStateMass) |>
  full_join(Input_Emission, by = c("Abbr", "RUN"))

varnames <- colnames(Plot_data)[2:(1+n_vars)]

plot_theme <-  theme(
    axis.title.x = element_text(size = 14),    
    axis.title.y = element_text(size = 14),    
    axis.text.x = element_text(size = 12, angle = 45, hjust = 1),     
    axis.text.y = element_text(size = 12),
    title = element_text(size=20)
  )

emiscomps <- unique(solved$Input_Emission$Abbr)

```

```{r Plots}
p1 <- ggplot(Plot_data, mapping = aes(x=varnames[1], y = EqMass)) +
  geom_point() + facet_wrap(vars(Abbr)) +
  scale_y_continuous(trans = 'log10')
p1

p2_data <-
  Plot_data |> pivot_longer(varnames,
                            values_to = "Variable value",
                            names_to = "Variable") |>
  filter(SubCompart == "river")

p2 <-  ggplot(p2_data, mapping = aes(x=`Variable value`, y = EqMass)) +
  geom_point() + facet_wrap(vars(Scale,SubCompart,Variable)) +
  scale_y_continuous(trans = 'log10')
p2

# p3_data <-
#   Input_Emission |> pivot_wider(names_from = c(Abbr,Unit), names_glue = "{Abbr}_Emis_{Unit}",
#                                 values_from = Emis) |>
#   full_join(solved$SteadyStateMass) |>   filter(SubCompart == "river") |>
#   pivot_longer(c(`aRU_Emis_kg.s-1`,`s2RU_Emis_kg.s-1`), values_to = "Emission_kg.s-1",names_to = "EmisComp")
# 
# p3 <-  ggplot(p3_data, mapping = aes(x=`Emission_kg.s-1`, y = EqMass)) +
#   geom_point() + facet_wrap(vars(Scale,SubCompart,EmisComp))
# p3

plots_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

for(i in varnames) {
  p2 <- ggplot(plots_data, mapping = aes(x = .data[[i]], y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) + 
  ggtitle("Mass in compartment at year ") + 
  labs(subtitle = "Uncertain emissions",
       x = i,  
       y = "Mass (kg)") +
  plot_theme                 
print(p2)
}

# Filter the plot data for the compartments that received emissions
EM_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

# Plot the emissions against the masses for these compartments
EM_p1 <- ggplot(EM_data, mapping = aes(x = value, y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) +
  ggtitle("Relation between emissions and mass") + 
  labs(subtitle = "Uncertain emissions",
       x = "Emissions (kg/s)",
       y = "Mass (kg)") + 
  plot_theme
EM_p1

```

### 1.2 Uncertain variables and deterministic emission case

#### Create tibble with samples for uncertain variables

Because we only use one set of emissions, we only have to create samples for the number of variables we want to use.

```{r Create samples 2, warning=FALSE, message=FALSE}
n_vars <- 3 # The number of variables you want to create a distribution for
n_samples <- 100 # The number of samples you want to pull from the distributions for each variable

lhs_samples <- optimumLHS(n_samples, n_vars) # Generate numbers between 0 and 1 using lhs
```

The rest of the steps to create the dataframe with samples are the same as for method 1.

```{r Get min, max and peak value of variable values, warning=FALSE, message=FALSE}
# Define the names of the uncertain variables
var1Name <- "kdeg"

var1 <- World$fetchData(var1Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "river")

# Set the parameters for the triangular distribution
var1$a <- var1$kdeg*0.5    # Minimum value
var1$b <- var1$kdeg*1.5    # Maximum value
var1$c <- var1$kdeg        # peak value (peak)

# Define the names of the uncertain variables
var2Name <- "kdeg"

var2 <- World$fetchData(var2Name) |>
  mutate(Scale = NA) |>
  filter(SubCompart == "air")

# Set the parameters for the triangular distribution
var2$a <- var2$kdeg*0.5    # Minimum value
var2$b <- var2$kdeg*1.5    # Maximum value
var2$c <- var2$kdeg         # peak value (peak)

# Define the names of the uncertain variables
var3Name <- "kdeg"

var3 <- World$fetchData(var3Name) |>
  filter(SubCompart == "agriculturalsoil") |>
  mutate(Scale = NA)

# Set the parameters for the triangular distribution
var3$a <- var3$kdeg*0.5    # Minimum value
var3$b <- var3$kdeg*1.5    # Maximum value
var3$c <- var3$kdeg         # peak value (peak)
```

Now this data needs to be combined into a tibble, and the function for the triangular distribution written earlier is applied to the tibble. The result is a nested tibble, containing the name, scale and subcompartment for each variable, and the sample data is nested. 

```{r Scale the samples to the distributions, warning=FALSE, message=FALSE}
params <- tibble(
  varName = c(var1Name, var2Name, var3Name),
  Scale = c(var1$Scale, var2$Scale, var3$Scale),
  SubCompart = c(var1$SubCompart, var2$SubCompart, var3$SubCompart),
  data = list(
    tibble(id = c("a", "b", "c"), value = c(var1$a, var1$b, var1$c)),
    tibble(id = c("a", "b", "c"), value = c(var2$a, var2$b, var2$c)),
    tibble(id = c("a", "b", "c"), value = c(var3$a, var3$b, var3$c))
  )
)

sample_df <- params

# Transform each LHS sample column to the corresponding triangular distribution
for (i in 1:n_vars) {
  a <- filter(params$data[[i]], id == "a") %>% pull(value)
  b <- filter(params$data[[i]], id == "b") %>% pull(value)
  c <- filter(params$data[[i]], id == "c") %>% pull(value)
  
  samples <- triangular_cdf_inv(lhs_samples_vars[, i], a, b, c)
  
  # Create a new tibble for 'data' with samples replacing original values
  new_data <- tibble(value = samples)
  
  # Update the data column in the sample_df
  sample_df$data[[i]] <- new_data
}
```

#### Prepare emission data

When using this method, all we need is one steady state dataframe with emissions.

```{r Create steady state emission dataframe 2, warning=FALSE, message=FALSE}
# Create the steady state emission dataframe
emissions <- data.frame(Abbr = c("aRU", "s2RU", "w1RU"), Emis = c(10000, 10000, 10000)) # convert 1 t/y to si units: kg/s

MW <- World$fetchData("MW")

emissions <- emissions |>
  mutate(Emis = Emis*1000/(365*24*60*60)) 

```

#### Solve

```{r Solve 2, warning=FALSE, message=FALSE}
World$NewSolver("UncertainSolver")

solved <- World$Solve(emissions, needdebug = F, sample_df)
```

#### Make plots

```{r Data preparation for plots}
Input_Variables <- 
  solved$Input_Variables |> unnest(data) 
Input_Emission <- 
  solved$Input_Emission |> unnest(Emis) 

Plot_data <- 
  Input_Variables |> 
# some units missing resulting in NA
  pivot_wider(names_from = c(varName,Scale,SubCompart,Unit), values_from = value) |> 
  full_join(solved$SteadyStateMass)

varnames <- colnames(Plot_data)[2:(1+n_vars)]

plot_theme <-  theme(
    axis.title.x = element_text(size = 14),    
    axis.title.y = element_text(size = 14),    
    axis.text.x = element_text(size = 12,angle = 45, hjust = 1),     
    axis.text.y = element_text(size = 12),
    title = element_text(size=20)
  )

emiscomps <- unique(solved$Input_Emission$Abbr)

```

```{r Plots}
p1 <- ggplot(Plot_data, mapping = aes(x=varnames[1], y = EqMass)) +
  geom_point() + facet_wrap(vars(Abbr)) +
  scale_y_continuous(trans = 'log10')
p1

p2_data <-
  Plot_data |> pivot_longer(varnames,
                            values_to = "Variable value",
                            names_to = "Variable") |>
  filter(SubCompart == "river")

p2 <-  ggplot(p2_data, mapping = aes(x=`Variable value`, y = EqMass)) +
  geom_point() + facet_wrap(vars(Scale,SubCompart,Variable)) +
  scale_y_continuous(trans = 'log10')
p2

# p3_data <-
#   Input_Emission |> pivot_wider(names_from = c(Abbr,Unit), names_glue = "{Abbr}_Emis_{Unit}",
#                                 values_from = Emis) |>
#   full_join(solved$SteadyStateMass, by = "Abbr") |>   filter(SubCompart == "river") |>
#   pivot_longer(c(`aRU_Emis_kg.s-1`,`s2RU_Emis_kg.s-1`), values_to = "Emission_kg.s-1",names_to = "EmisComp")
# 
# p3 <-  ggplot(p3_data, mapping = aes(x=`Emission_kg.s-1`, y = EqMass)) +
#   geom_point() + facet_wrap(vars(Scale,SubCompart,EmisComp)) 
# p3

plots_data <- Plot_data |>
  filter(Abbr %in% emiscomps)

for(i in varnames) {
  p2 <- ggplot(plots_data, mapping = aes(x = .data[[i]], y = EqMass)) +
  geom_point() + 
  facet_wrap(vars(Abbr)) + 
  ggtitle("Mass in compartment at year ") + 
  labs(subtitle = "One set of emissions",
       x = i,  
       y = "Mass (kg)") +
  plot_theme                 
print(p2)
}

```

## 2. Probabilistic Dynamic Solver 
